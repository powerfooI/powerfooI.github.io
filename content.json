{"pages":[{"title":"关于我","text":"在校大学生，数学不太好，喜欢新事物，正在努力学习。 我是个追求从容的人，什么是从容呢？我觉得就是尽可能的把握自己的时间，让自己忙的时候不那么忙，闲的时候不那么闲，这样就可以让自己不至于奔走至狼狈，也不至于闲散到颓废，少一些无可奈何的身不由己，少一些心血来潮的浅尝辄止，这应该就是我眼中的从容吧。 生活是什么呢？生活是这样的，有的事情还没有做，一定要做的……另有些事做了，没有做好。明天不散步了。——木心《哥伦比亚的倒影》 今天还散不散步呢，还是得好好想想。","link":"/about/index.html"}],"posts":[{"title":"对Python,Golang和C++三种语言GC机制的简单调查","text":"调查背景在公司一项任务是需要调用Python的SDK爬取相关的数据信息，数据的量在10亿这个量级，故不能够一下子得到结果。这个程序运行十来天的可能性比较大，但是问题来了，程序跑过一阵子（1小时）之后爬取效率明显降低。重启之后效率恢复，这就让人有点不爽了，本来数据量就多，用初速度爬取也需要十来天，这样一减速得爬到什么时候呢？通过使用top工具，观察到爬虫脚本在运行过程中占用的内存从800MB上升到了1.4GB，速度也随内存占用量的上升而减慢。（图片来自MacOS的top，与程序的运行环境中的top不太一样）我猜可能是内存泄漏了，各种查资料之后用python的gc和objgraph进行程序内存使用情况分析。虽然针对于爬虫程序的分析无果，但是对GC机制有了一点兴趣，于是稍微了解了一下。 下文的 GC 既指 Garbage Collection， 也指 Garbage Collector。 接触Python一年多，Golang九个月，C++是大一时OOP课上教授的语言。其实都只是了解了皮毛，仅仅停留在“会用”这个层面。 三种语言的GC机制Python1. 引用计数引用计数是一个很简单的实现方式，顾名思义： 当一个对象被引用时，该对象的引用次数+1； 当引用这个对象的另一个对象被GC回收时，该对象的引用次数-1；当GC监测到某对象的引用次数为0时则将该对象回收。 但是这个方案无法解决循环引用。 2. 分代回收根据对象的存活周期不同将内存划分为新生代和老年代，存活周期短的为新生代，存活时间长的为老年代。这样就可以根据每块内存的特点采用适当的收集算法。在新生代对象中进行高频回收，在这次回收中没有被清理的对象移动到老年代对象中，老年代对象执行低频回收。 上面是分代回收的定义，但是python没有简单的把对象分为新和老两个代际，而是分为了三代。每一代的对象达到了一定的数量（Threshold）之后GC会执行相应代际的对象回收，这个阈值是可以通过gc包进行设置的（gc.set_threshold），我调用gc.get_threshold()得到的结果是(700, 10, 10)。不像引用计数，分代回收是可以进行控制的，甚至是关闭。如果觉得GC太频繁造成了性能瓶颈，那么可以提高阈值，降低GC频率。 Golang1. STWGolang的早期版本被无数人所诟病的问题之一就是它的GC，它用的是标记清除方法，也叫Stop The World(STW)。该方法从根变量开始迭代，遍历所有被引用的对象，能够访问到的都标记上“被引用”；之后对没有标记过的对象进行清理，即回收不可达的对象。但是每次执行该算法都会让正常执行的内存负荷型程序出现明显的卡顿，这也是为什么该方法又被叫做STW的原因。 2. 三色标记法该方法是对标记清除算法的改进，原理如下： 起初所有对象都是白色的； 从根对象出发扫描所有可达对象，标记为灰色，放入待处理队列； 从队列取出灰色对象，将其引用对象标记为灰色放入队列，自身标记为黑色； 重复步骤3，直到灰色对象的队列为空。这时仍为白色的对象被当作垃圾回收。 下面是演示图： C++ In early programming languages, developers were responsible for all memory management in their programs. This meant before creating a list or an object, you first needed to allocate the memory for your variable. After you were done with your variable, you then needed to deallocate it to “free” that memory for other users.[2] C++就是early programming language，它较Python和Golang而言更偏底层和接近系统，将内存管理的工作交给程序员来完成。简而言之，就是没有GC（当然后来的C++11、14的新特性在此不提及）我之前写的某程序就因为想要释放整个数组的空间但是只写了delete xxx而不是delete[] xxx，仅释放了数组首位元素的空间，导致了剩余所有元素内存资源的浪费。为了减轻程序员手动管理内存的痛苦，C++11推出的智能指针算是一个宝贝。 参考资料 GO GC 垃圾回收机制 Python Garbage Collection: What It Is and How It Works 如何理解智能指针？ - 知乎","link":"/2019/06/12/GarbageCollectionSurvey/"},{"title":"ESLint 入门","text":"背景最近一两年写前端项目时一直都有接触 ESLint，很多文档和博客也一直都推荐使用开发者 ESLint，但是一直以来都没有好好地学习过它。最近因为使用 Nuxt 开发时 ESLint 缓存出问题导致浪费了半个小时，我越发觉得有必要深入地了解一下这个前端开发中最常使用的代码风格规范工具了。（不得不说，Nuxt 这个框架真的有点难用。） ESLint 的用途和初衷ESLint 是在 ECMAScript/JavaScript 代码中识别和报告模式匹配的工具，它的目标是保证代码的一致性和避免错误。维基百科上这样解释的：lint, or a linter, is a static code analysis tool used to flag programming errors, bugs, stylistic errors, and suspicious constructs. 就是说 ESLint 是写 javascript 时用来分析静态代码是否存在语法错误、代码风格错误和可疑结构的工具。 ESLint 的配置文件配置文件基础配置文件可以使用 .js, .yaml/.yml, .json 格式的文件和 package.json 中的 eslintConfig 属性来定义。读取的优先级如下： .eslintrc.js .eslintrc.cjs .eslintrc.yaml .eslintrc.yml .eslintrc.json package.json 注：eslint 只会读取优先级最高的一个配置文件。 最重要的 rulesESLint 的配置文件通过配置检查规则来给代码做静态检查，rules 对象中的键值对都代表一个规则，规则的值是一个数组，数组的第一个值是规则的检查力度，从 0 到 2 代表检查的力度越来越严格，0 代表不提示，1 代表给出 warning，2 代表给出 error。也可以直接用力度单词表示，如”off”, “warning” 和 “error”。数组第二个及以后的值表示的是传给该规则的参数。 下面给的配置文件片段规定在项目中 1. 如果使用了分号则报错；2. 引号只能用双引号，使用了单引号就会报错。 .eslintrc.js123456module.exports = { rules: { semi: ['error', 'always'], quotes: ['error', 'double'], },} 共享规则库另外，ESLint 还可以使用其他共享规则进行扩展。在配置文件中使用 extends 即可，如下面的一行配置项表示引入了 eslint 官方推荐的规则。（官方非常推荐使用这个规则库） .eslintrc.js123module.exports = { extends: 'eslint:recommended',} 当然有 recommended 就有 all, 但官方不推荐在生产环境下使用 all 这个共享库，因为其中的核心规则会随着版本的变化而改变，会导致预料之外的情况。 引入第三方规则库会有三种效果：1. 打开相应的规则；2. 改变检查力度但是不修改其它选项；3. 直接覆盖原本的规则。 使用插件eslint 的插件其实就是一个 npm 包，可以给 eslint 提供包括但不限于加入新规则和导出共享规则的功能。如下面的配置文件就引入了 react 的 eslint 插件。 1234567module.exports = { plugins: ['react'], extends: ['eslint:recommended', 'plugin:react/recommended'], rules: { 'react/no-set-state': 'off', },} Glob 模式匹配eslint 运行后会默认在指定的目录下对所有的 .js 文件进行扫描，如果在配置文件中使用了 overrides 参数，则可以对需要进行检测的文件进行指定。如下面的配置文件则指定扫描 bin/*.js 和 lib/*.js 并排除了所有的测试文件。 1234567891011121314module.exports = { rules: { quotes: ['error', 'double'], }, overrides: [ { files: ['bin/*.js', 'lib/*.js'], excludedFiles: '*.test.js', rules: { quotes: ['error', 'single'], }, }, ],} 使用配置注释在文件的开头使用 eslint 开头的注释语句可以控制 eslint 对该文件的检测行为。在配置文件中如果配置了 noInlineConfig 属性为 true 的话，就不能使用文件内注释的方式进行配置了。下面摘抄几个配置注释的例子： 123456789101112131415161718console.log('1. 整个文件不检查 ===， 使用分号会报错')/* eslint eqeqeq: &quot;off&quot;, semi: [&quot;error&quot;, &quot;always&quot;] */console.log('2. 在 -- 之后给出一些说明')/* eslint eqeqeq: &quot;off&quot;, curly: &quot;error&quot; -- Here's a description about why this configuration is necessary. */console.log('3. 在此文件中直接禁用/启用 eslint')/* eslint-disable *//* eslint-enable */console.log('4. 整个文件中禁用某些规则')/* eslint-disable no-alert, no-console */console.log('5. 下一行禁用某项规则')// eslint-disable-next-lineconsole.log('6. 这一行禁用规则')console.log('foo') // eslint-disable-line 常用配置项摘自另外一篇博客。 123456789101112131415161718192021222324252627282930313233module.exports = { 'no-var': 'error', // 要求或禁止 var 声明中的初始化 'init-declarations': 2, // 强制使用单引号 quotes: ['error', 'single'], // 要求或禁止使用分号而不是 ASI semi: ['error', 'never'], // 禁止不必要的分号 'no-extra-semi': 'error', // 强制使用一致的换行风格 'linebreak-style': ['error', 'unix'], // 空格2个 indent: ['error', 2, { SwitchCase: 1 }], // 指定数组的元素之间要以空格隔开(,后面)， never参数：[ 之前和 ] 之后不能带空格，always参数：[ 之前和 ] 之后必须带空格 'array-bracket-spacing': [2, 'never'], // 在块级作用域外访问块内定义的变量是否报错提示 'block-scoped-var': 0, // if while function 后面的{必须与if在同一行，java风格。 'brace-style': [2, '1tbs', { allowSingleLine: true }], // 双峰驼命名格式 camelcase: 2, // 数组和对象键值对最后一个逗号， never参数：不能带末尾的逗号, always参数：必须带末尾的逗号， 'comma-dangle': [2, 'never'], // 控制逗号前后的空格 'comma-spacing': [2, { before: false, after: true }], // 控制逗号在行尾出现还是在行首出现 'comma-style': [2, 'last'], // 圈复杂度 complexity: [2, 9], // 以方括号取对象属性时，[ 后面和 ] 前面是否需要空格, 可选参数 never, always 'computed-property-spacing': [2, 'never'],} 命令行工具使用 eslint 的同名命令行工具可以对代码进行分析并将分析报告输出，其主要的使用方式是 eslint [options] [file|dir|glob]*，即最终的分析对象可以是文件、目录和 glob。可以通过选项对工具的行为进行自定义，下面总结一些比较重要的命令行工具选项。 --ext: 指定检测的文件拓展名，eslint 将在给定目录中对指定类型的文件进行扫描检测。如果不给出该选项，默认是 *.js； --fix: 修复检测出来的问题，但是有时候给了这个选项也修复不了相应的问题，这时候就得手动修改相应位置的代码了； --fix-dry-run: 修改检测出来的问题但是不进行保存； --cache: 传递该参数运行命令行工具的话会将检测结果进行缓存，下一次再执行缓存模式时将只针对有变化的文件进行扫描； --init: 初始化 eslint 的配置文件，传入这个参数会进入 eslint 的配置向导，从而生成符合用户期望的配置文件。配置向导如下所示：","link":"/2021/03/28/EslintTaste/"},{"title":"再见了，兵荒马乱的 2022","text":"今天是2022年12月31日，2022年的最后一天，先给年初的自己说一声对不起：年初立的 Flag 基本没有一条是顺利达成的，我以为目标量化以后就可以逐项实现，但还是高估自己的执行力和时间充裕程度了。今年是我第二个本命年，本应过的虎虎生风，生龙活虎，但是现实没有我想象中那么精彩，但有一些事情还是值得记载。这一年我在专业上经历了迷茫，在情感上遇到波折，在工作上也遭遇了挑战，大环境上也在年底迎来了疫情政策的转折。我想对这一年做个小小的总结，也对明年做些展望和规划。 面对未知要乐观现在回看今年写的几篇博客发现自己还是比较幼稚，喜欢用学生思维来思考问题：“我不想写前端代码了”“我为什么要用 GraphQL 来写前端代码”云云，当时除了觉得前端代码比较聚焦视觉和交互以外，还认为总是写前端代码对之后找基础研发相关的工作不是很有利。现在回过头来看，与其花时间纠结自己一直写前端代码对未来有什么不利的影响，不如把这部分时间投入到自己想学、想做的事情当中。 畏畏缩缩地权衡着每一种选择的利弊，却从未迈出哪怕一步。这或许可以说是谨慎，但是过于谨慎只会让人止步不前。然而我不是自发主动地参悟到这一点，而是参加了今年的秋招后被迫察觉的。我当然没有参加过往年的秋招，但是今年整个社会都在传递就业方面的焦虑情绪，可以大体了解到今年秋招应该是比前两年困难些许的。 暑假本来可能有机会可以去字节跳动实习，但当时因为公司研发任务较重没办法抽出时间参与，错过了一段具有较高含金量的实习经历，我不以为然，觉得没有暑期实习没什么大不了。想着公司手头的事情忙完了再拿出一段时间好好准备秋招，但手头的事情永远忙不完，我就永远没有抽出时间进入准备秋招的“状态”。七月底投了字节的提前批，在 LeetCode 上刷了几十道题就开始面了，第一次面试过于紧张，基础知识回答得还算满意，写代码环节脑子一片空白。稀里糊涂到了三面主管面，这回更紧张了，表现一般最后给挂了。 通过字节提前批的经历我有了心理预期：没有完完整整的时间窗口可以用来专心致志地准备一件事情，不能再用准备高考的状态来准备秋招了。真如鲁迅先生所说，时间就像海绵里的水，只要愿意挤总会有的。那之后我白天去公司上班，晚上回学校刷题复习，八月底九月初密集投递简历，不断润色打磨自己的面试状态，经常一天面试2～3轮，着实是没有硝烟的战场。近三个月的秋招让我产生了线上面试 PTSD，戴上耳机打开会议软件就会自动联想到面对面试官做自我介绍的场景。当然这种 PTSD 不是害怕，是厌倦。 毛主席说过要在战略上藐视敌人，战术上重视敌人，我一直秉持这样的行事态度，力求对待一切事情都“抱最大希望，做最坏打算”，这也要求我对待事情做最好的准备，我喜欢准备 Plan B，在原定计划无法顺利开展时拥有备选方案是令人安心的。秋招对我来说很重要，所以准备需要更充分。（虽然最了最坏打算，但是本能地还是希望有好的结果）一直在准备，从来没行动，这是我对失败的不确定性的恐惧，是害怕失败的二阶导数。以前常听罗翔老师讲段子，他曾提到一句“对待已知的事情要谨慎，对待未知的事情要乐观”。自己熟悉或擅长的东西自己不上心往往容易出差错，我家这边有句谚语的意思大概就是“淹死的往往都是会游泳的”也讲得是这个意思，所以面对已知的事情要敬畏，要谨慎；面对未知的事情自己没有什么办法，只能尝试不同的方法来面对未知，消除未知带来的恐惧，在原地踌躇不前是无法解决问题的。 不过好在我开始行动的时间也不算晚，面试到九月下旬时渐入佳境，也陆陆续续收到了一些大小厂的 Offer（哈哈也包括字节的正式批），结果还算满意吧。 重度“效率瘾”患者“效率瘾”是我在调研笔记软件时看到一篇博客里提到的名词，我觉得很有趣。其大概含义是指如今不少人的最大爱好就是追求高效：今天在应用商店打开“效率”类目查看是否有新的效率提升软件可以帮助自己提升效率，明天在网上调研一番市面上哪款笔记软件比较适合构建知识库，后天开始思考应该如何分配笔记的段落结构使得内容详略得当，信息密度提升。他们执行效率最高的事情就是寻找提高效率的方法，自己却从未尝试或坚持将方法付诸实践，相当于提效的二阶导数。这些人可以说是“差生文具多”，可以说是学习上的“工具党”，甚至可以说是学习之前要做好万全的准备，争取一步到位。 最惊悚的是看到这个名词之后我发现自己就是”效率瘾“患者，而且是重度。我潜意识里希望自己行动之前做好万全的准备，开始时就是最好的也是最终的状态，这很理想化，没有可行性。 工具是次要的，内容是重要的。调研了若干笔记软件，找到了当前最先进的又如何，其中存放着几篇笔记呢？看到这篇博客我被吓了一跳，赶紧关掉所有介绍和对比笔记软件的浏览器标签页。经过一些思考，我总结了两条克服“效率瘾”的办法： 重视内容轻视工具，集中精力投入生产，学习是知识在大脑里的 I/O 过程，看到重要的内容记录下来，之后复习时再整理，整理的过程也是知识碎片重组的过程； 用软件工程的思维看待事物，软件需要不断的迭代更新，成功不是一蹴而就的。生活、工作也一样，不完美和不如意是必然的，有迭代的勇气和能力就足够了。 愿自己能够尽早戒除“效率瘾”，把时间精力用在做有用功上。 对 2023 年的期待今年五月开始打比赛，六月底恋爱分手，紧接着七月底开始了长达三个月的秋招历程，再伴随着疫情抬头我十二月初就早早回到家里远程办公，刚到家就得知疫情防控政策开始放宽，于是等待变阳。今年下半年没有太多“自己的时间”，什么是自己的时间我也说不准，只是一直这么觉得。我无比期待 2023 年能够恢复到 2019 年的生活，我现在已经想象不到出门不用戴口罩的感觉，回忆不起来自由出入学校、出入北京的体验了。疫情三年抹去了研究生阶段诗与远方中“远方”的部分，这诗也唱得呕哑嘲哳，疫情让我本科线上毕业，千万让我毕业时能和北京当面好好道个别。 至于计划，争取每个月发布至少一篇博客吧。 Bye～","link":"/2022/12/30/Goodbye2022/"},{"title":"好久不见，前端再见","text":"断断续续写前端项目也有好几年了，从大二接触 Javascript 和 Vue 时的兴奋，到接触小程序和 React 时的“渐入佳境”，再到这段时间的感到无比疲惫，我希望我在前端开发上大规模投入的阶段先暂告一段落了。为什么有这样的疲惫感呢？原因总结起来有以下几点： 前端开发面临的大多不是技术问题，是产品问题或美学问题，最终目标是让用户满意； 前端开发过于琐碎，需要处理的细枝末节极多，每个页面元素都有相应的状态需要管理； 前端难于抽象，对应到用户上则表现为具体业务需求是千变万化的。 写前端的疲惫感从技术上来说绝大部分前端应用并不需要考虑代码的优化，而是需要“取悦”用户，这应该是最让我无法忍受的了。因为前端应用面向最终用户，看得见摸得着的应用就会让用户有点评的冲动，而除了基本的程序正确性问题外，诸如“我觉得这里不好看”这样主观且不确定的问题占绝大多数。相较于后端而言，前端应用面向的用户不知道也不关注技术问题，他们对应用提出的问题是不收敛的，且提出问题的同时往往伴随着需求变动。 而回归到技术上，与其说是我选择了前端框架，不如说是我选择的 UI 组件库替我焊死了框架的门，真正做到 面向 UI 组件库的编程 。目前我们普遍使用的 React + AntDesign 的组合已经成了标准配置，图快写出来的所有的应用外观上和代码上都几乎一样，让我有些视觉疲劳和精神疲劳。 疲劳状态下需要转移注意力，换换脑子接触新的东西，近期发现了重编译时的轻量前端框架 Svelte 的确让我耳目一新，简单清晰的 API 和朴素的文件布局和它的名字完全吻合，让人觉得 Web 开发又回到了似曾相识的从前的模样，熟悉又清新。但很快美梦就破碎了，当我准备用它重构自己用 React 写的网站时发现消息提示，模态对话框，表单验证等前端开发常见场景问题都没有太好的解决方案。回顾了 Bootstrap，有刀耕火种的味道。可能我属于“急于求成”“基础不扎实”的前端开发者吧，如果有时间和机会好好打磨 UI 组件，调整样式和布局应该能够达到非常好的效果。但 React + AntDesign 就跟吃快餐一样，风味欠佳但是效率很高。 现在我觉得是实际业务选择了我，前端框架选择了我。 当我谈写代码时我谈些什么当我提到写代码，脑海里想的是借助程序充分利用计算机的能力，达到我需要完成的计算任务。程序的状态应被准确地刻画，程序的输入输出应被良定义，程序的边界应当较为清晰，程序的正确性可以被验证…而这些与前端开发不能说是毫不相干，也可以说是相去甚远。 人是会犯错的，用动态语言写代码错误频出，而因为我能力有限，用动态语言写前端代码只会使得错误跟我玩捉迷藏，更何况还得面对各路用户提出的需求和美学问题。我希望我写代码时能够保持足够长的、不被打扰的专注时间，让我可以设计并实现程序，而不是时不时考虑表格 A 缺了字段，按钮 B 应当换成主色等琐碎的问题。下面这张图就是上个月某两周的代码提交次数统计情况，在前端应用的开发中需要处理的事情和写的代码都是极其琐碎且没有局部性的。我不认为这么多次的提交都具备平均的单位价值，但可以体现写的代码是东一榔头西一棒子的。 当然这些都是我的主观感受，无知者无畏，我只是窥到了前端的冰山一角便自觉全面接触后难以接受想着要逃。我很喜欢 Vue React Svelte 这些项目，也希望有朝一日可以自己可以搭建出这样的框架。用框架写前端应用和实现前端框架是完全不一样的概念，前者针对业务，后者面向系统。我计划在之后的时间里深入到软件系统的设计与实现当中，在可接触的项目范围内开始转向后端于我而言是理想的开端。编写相似的业务代码给我带来的技术提升和成就感与日俱减，尤其是我饶有兴致地用颇为巧妙的方法实现的前端应用被用户主观地认为“不好看”或者“不易用”时，很难避免这些对应用本身的批评转嫁到自己身上，实现得不好可能也有，但是这种因素占比是多少呢？ 希望一人独处的念头，始终不变地存于心中。所以一天跑一小时，来确保只属于自己的沉默的时间，对我的精神健康来说，成了具有重要意义的功课。至少在跑步时不需要和任何人交流，不必听任何人说话，只需眺望周围的风光，凝视自己即可。这是任何东西都无法替代的宝贵时刻。 —— 村上春树 写前端的收获抱怨了这么多，不是想表达我对前端开发的深恶痛绝，而是“爱之深责之切”(?)。我仍会关注前端领域的发展，甚至还会在自己的网站里尝试新的前端技术，但对于我而言它已经成为“庐山烟雨浙江潮”。它给我带来的收获有几方面，最主要的就是产品思维、审美提升和巩固 Web 基础。 首先产品思维就是站在用户的角度思考产品的问题，以用户为中心。而用户就是更注重产品的美观性、易用性而不注重实现方法和程序效率，软件产品本身不仅是代码和程序，美术素材、按钮图标、菜单样式等等都是其中重要的部分。因为前端应用直接面向最终用户，所以前端开发其实也是在做产品，当然如果纯粹机械地将原型图还原成前端应用则另当别论。 审美提升则是主观和隐性的。因为我所做的前端应用大多是 ToB 模式，不同于电商类应用，没有引流新用户的需要，所以几乎所有界面都是简约风格的，久而久之我对应用的设计风格就有了简约的偏好。最直接的影响是发现“丑”的应用数量增多，间接影响是当我听完一段应用的功能描述后可以在脑海里描摹出大致的页面设计方案，何处需要做一些留白，元素如何合理布局，如何让页面观感舒适等。审美的提升不仅体现在页面实现上，也体现在代码风格上，能写美观的地方我会尽量优化，目录结构、文件命名、甚至是注释的写法也要统一(/** */、//、/* */)。 巩固 Web 基础的巩固则直截了当，DOM API、Typescript、浏览器兼容性 甚至是 jQuery 等杂七杂八的东西都有接触，也开始封装发布自己的 UI 组件和实用工具 NPM 包，成为 NPM 包玩家。Svelte 的出现也把基于 Virtual DOM 前端框架的势头稍微拉回了经典的开发风格，让我体验了一把文艺复兴。 后续计划前段时间业余时间学习了 Rust，希望能够借助 Rust 的学习路径复习操作系统、计算机组成原理和数据库原理等基础知识。阅读 Rust 的中英文文档及博客后深感深切感受到了大一从 C/C++ 上没有感受到的魅力，Rust 编译器像严格的编程教练，用极为严格的语法要求我们写出合规合法的代码，这样一来通过编译器检查的代码就已经达到较高的标准；Rust 中 所有权 和 生命周期 的机制也十分巧妙，能够最大限度地避免内存泄漏和野指针的问题；作为 Mozilla 推出的现代编程语言，内建的类库和原生的 API 都比较趁手。 3月末 Golang 发布了 1.18 正式版，终于推出了泛型编程的特性，到现在还没有真正上手写呢，是时候体验一番了。 后续计划主要用 Golang 或 Rust 这两种编程语言，配合 GraphQL 搭建可拓展的后端服务；自己整体的工程方向朝着微服务、云原生的方向靠拢，尽量扎进计算机系统的核心和底层。","link":"/2022/05/09/GoodbyeFrontEnd/"},{"title":"我毕业了","text":"从 2016 年 8 月来到清华上学，到现在已经快要五年了。近期借着学校给给 2020 届补办毕业典礼的契机，得以穿上学士服跟朋友们同学们一起拍毕业照。课程学习生活暂告一段落，心里有很多感慨不吐不快。 大概从以下几个方面来聊一聊吧：专业选择给我的影响，清华之于我的意义以及自己的成长和收获。 专业选择用 697 分的高考分数结束了漫长枯燥的高中生活之后，我进入了清华大学软件学院学习，专业名称是软件工程。其实我填报志愿时对清华的专业不是很了解，在招生组老师和学长学姐的介绍之下选择了这个和计算机相关性最大的专业。（对没错，当时我们省不招计算机） 差距很大作为小镇做题家的零基础计算机小白，在入学之后很快地就感受到了和其他同学的差距，尤其是编程作业一些同学一小时完成而我要花上一下午甚至一整天的时候。清华的学期中学习压力很大，26 学分左右的课程基本上意味着一周五天都是课，每天都有作业要做。当时编程能力十分落后带来的影响导致一些基础数理课也有些吃紧，好在最后都没有触到挂科这个的情况。我经常问我室友或者年级里的其他同学作业问题，怕总是问一个同学把他问烦我就在一些同学之间来回换着问。在这里要由衷感谢几位大神和我的室友们。 兴趣渐浓我从小就对电脑这东西比较感兴趣，不管是电脑游戏还是一些电脑应用，总是喜欢自己捣鼓。来到软件学院也算是得偿所愿，尤其是很多课程的大作业（或许有的学校叫做“课程设计”）都是写游戏，很对我的胃口。本科应该一共写了 3 个游戏，虽然质量都很差，但是写的过程还是快乐的。我发现我喜欢自己造一些东西出来，写一个游戏、发布一个包或者库、开发一个系统这些都是比较吸引我的事情。比起考试这样的紧张刺激的课程考核形式，开发游戏或者系统这样成果看得见摸得着的事情，让我觉得更加踏实。可能总的来说我还是比较希望规避不确定性，拥抱更多的确定性吧。或许这也从一个方面体现了其实我不是天赋型选手，勤能补拙应该是我需要考虑的第一要义。 大三上了《软件工程》这门课，和另外三个队友真刀真枪的开发一个系统：需求分析、原型设计、技术选型、数据库设计、功能实现、系统测试、文档撰写这些软工流程我们完整地体验了下来，最后课程成绩比较好。我也发现了我确实挺喜欢写代码的。后来的数据库、计算机网络等课程，包括后来到旷视实习的经历都进一步加深了我的兴趣。让我逐渐明晰喜欢的事情。 现在开发的琴房预约系统目前已经上线，虽然之前的队友不太有热情来维护这个项目了，但是就算是我一个人我也会把这个项目好好维护到我自己毕业；作为辅导员，我自己开发了一个系统给自己和同学们用来查询成绩和排名，也给其他辅导员开发了一个计算排名和查询成绩的网站；面对新颖的、高效的、优雅的技术我总是会心生向往，很难控制自己想去了解一下的冲动，可能就是喜欢折腾吧。每次想尝试一个东西我都会在 github 上创建一个叫做 XXX-taste 的 repository，现在类似的 repo 好像已经有十来个了。我觉得目前我对我所做的事情还是保有相当的热情，也愿意为之投入更多的时间。 清华之于我在清华待了五年，要说它给我带来了什么或者让我失去了什么可能很难用言语梳理出来，列一下现在能想到的几点吧： 清华给我上的第一课就是接受平凡，在高中三年大大小小的考试中我很少考第二名，但是到了清华要接受自己是个计算机小白，排名只在中等水平的事实。 如果拿不了95分，那么80分也挺好，好好完成课业任务，心态要稳。与其跟别人在成绩上卷，不如做自己感兴趣的、有意义的事情。 大学里学的不只是课内知识，更要学习待人处事的方法，增强面对挫折的勇气，拓宽所处世界的视野。 朋友很重要，尤其在校园这个小社会当中，他们就是自己的靠山了。 入党是一件非常庄严的事情，如果不是明确清晰地认同党的路线和纲领，请不要申请入党或者发展这样的同学。 不要总是窝在寝室打游戏，户外真实的风和阳光比游戏中的虚拟更加美好。 总结和展望大学里拿过一些4.0，也险些挂了某些课程；当过班长、学生会主席，现在还在继续做着辅导员这份学生工作；感情方面谈过异地恋、异国恋，当过舔狗，被劈过腿。生活体验可以说是非常丰富了（甚至有些离谱），从这些经历中得到了什么成长呢？得到了较强的心理承受能力吗哈哈，挺过挂科边缘的压力还是需要一定的承受力的；一边忙着各种课程作业，一边手忙脚乱地筹办学生节也是很难得的体验，更何况我们还产出了很多优秀的文艺节目；谈的几段感情都是异地，美好的回忆当然是有的，但是遗憾更多吧，这几段经历都无一例外地让我变得更加成熟了。 距离完全跃入人海还剩下不到两年的时间，通过这五年的时间我应该能够以更好的姿态来迎接未来两年的挑战，也希望剩下的两年里可以多做些自己想做的事情，不留遗憾。冲鸭~","link":"/2021/06/29/Graduation2021/"},{"title":"Github Actions的基本使用","text":"背景在毕业设计时捣鼓了一会应用的持续集成(Continuous Integration, CI)和持续部署(~ Deployment, CD)，发现确实可以为自己省下很多力气： 不用每次把代码通过 scp 或者 sftp 传到服务器上再 build 运行 也不用在本地交叉编译之后再传到服务器上 之前在公司实习时所有的分支合并都会涉及到 CI 和 CD，当时为了让代码编译通过费了很多心思。虽然自己push代码的时候比较费劲，但是确确实实可以给应用的部署和可用性提供保障。 最近在看阮一峰大神的技术博客时偶然看到了Github Actions的入门基本教程，发现 github 把 CI 脚本商品化、组件化放到 Marketplace 里供用户挑选和使用是一个非常不错的思路，让 github 的开源文化更加吸引人了。我把上面那篇博客看完之后发现其实和 Travis CI 差不多，或者说其实所有的 CI 系统都差不多。抱着接触新事物的热情，我还去看了 github actions 的官方文档，下面对我所了解到的一些信息进行一个汇总。 核心概念Github actions 中有下面几个重要的概念，直接上原文档： Workflow Jobs Steps Actions Runner 1. Workflow 工作流，工作流是由在 git 项目目录中的 .github/workflows/*.yml 文件定义的自动执行程序，可用于项目的构建、测试、打包、发布和部署。工作流又由一个或多个任务组成。 2. Jobs 任务，由一组步骤组成的单位。在工作流文件中可以定义任务如何运行：是并行执行还是顺序执行，以及以什么条件、什么顺序执行。在 Github-hosted 宿主机中，每一个任务都是在一个全新的虚拟环境中运行的。 3. Steps 每一个步骤都是一个单独的任务，可以执行 shell 命令或者是执行 action。一个任务里的所有步骤都是在相同的虚拟环境中执行的，使得不同的步骤可以通过文件系统共享信息。 4. Actions 翻译成动作有点太难听了，还是就叫 Action 吧。Action 是工作流中最小的可移植构建模块，你可以创建自己的 action，也可以使用社区里的 action，还可以对公开的 action 进行DIY。如果在工作流中使用，必须将 action 包含在步骤当中。 5. Runner 我把它叫做宿主机，宿主机分为两种：Github组装的和用户自组装的，他们存在着一些不同。宿主机等待用户的各种任务，一旦宿主机接受了任务，它会执行任务里的 actions，并把运行进度、日志和结果传给 github，用户可以在 actions 页面中查看这些信息。日志最多保存 30 天。 简单使用目标我的博客用的是 hexo 在 github pages 上构建的，博客所在位置是一个 repo，hexo 源码所在位置又是另一个 repo，我希望可以合并这两个 repo。或者退而求其次，我希望可以一次 commit 实现两个 repo 的 work done。这就要求我： 在源码 repo 处启用 actions 进行自动构建 将构建好的 repo 源码推送到 gh-pages repo 当中 在 Marketplace 中寻觅我找了四个公开的社区 action 想进行使用，发现他们存在着各式各样的问题，难怪最多的一个项目也只有 21 个 star。 自己写工作流文件deploy.yml123456789101112131415161718192021222324252627282930313233343536name: deployon: push: branches: [ master ]jobs: build: name: Build runs-on: macos-latest steps: - uses: actions/checkout@v2 - uses: actions/setup-node@v1 - run: npm install - run: npm install hexo -g - run: npm install hexo --save - run: hexo g - name: config git run: git config --global user.email &quot;$EMAIL&quot; &amp;&amp; git config --global user.name &quot;@NAME&quot; env: EMAIL: *** NAME: *** - name: bind github remote run: | cd ./public git init git remote add origin https://$PERSONAL_TOKEN@github.com/$USERNAME/$USERNAME.github.io.git env: USERNAME: fool-wang PERSONAL_TOKEN: $ - name: push public run: | cd ./public git add . git commit -m &quot;auto deploy&quot; git push -f origin master 该工作流每次在我向 master 分支 push 代码时会触发，其中任务只有一个 build，我给他设定的名字也是 Build。runs-on 指定宿主机，在这里因为我的电脑是 macos 系统，所以我希望宿主机可以和我的电脑操作系统相同，所以选择了 macos-latest。下面到了最最关键的步骤，一条一条地解释我做了什么（其实我也知道我的 push -f 很不优雅）： 用了官方的 actions/checkout 来获取 repo 文件内容 用了官方的 actions/setup-node 来获取 node.js 运行时环境，其实主要就是需要 npm 运行 npm install 命令，为项目安装依赖 运行 npm isntall hexo -g 命令，为虚拟环境全局安装 hexo 运行 npm install hexo --save 命令，这一步我非常不解，但是如果没有这一步之后的步骤会报错 运行 hexo g 命令，生成 public 静态页面文件 配置 git 信息，通过环境变量传入我的邮箱地址和姓名信息 通过我的 personal access token 将博客 repo 绑定到生成的 public 文件夹远端 将 public 内的文件强制 push 到博客 repo 中，希望实现文件替换，也就是实现了部署过程 问题，大问题我发现宿主机内执行 hexo g 命令生成的文件与在本地电脑上生成的文件不一致，下面放几张图片： 上图是本地执行命令的生成的文件，下图是宿主机执行命令生成的文件，差别那么大就很离谱。 更离谱的是，博客 repo 上新部署的 index.html 文件内容是空。 结语Github actions 的基本使用倒是已经掌握了，但是没办法实现博客源码自动构建和自动部署是有点困扰我，其中最神奇的问题就是 hexo g 生成的文件不同。不知道这个是我的打开方式错误，还是 github actions 环境有问题，还是 hexo 有问题。（最后一般都是我有问题） Github actions 使用体验不错： 在私有 repo 中也能够免费使用，真心觉得微软爸爸好 任务执行流程、日志和结果呈现十分友好 marketplace 的思路新奇，有许许多多开发者贡献代码，社区活跃度高，今后一定会变得更易用 构建失败后会有邮件提醒 之后有时间还会继续深入了解 actions，争取把今天遇到的问题给解决掉了。 后续hexo g 命令生成的文件与在本地不同是因为…我漏掉了 git clone 模板库的步骤。第二天早上在 hexo g 之前补上了下载模板库的命令之后就正常工作了。熬夜害人熬夜害人。 参考文献 GitHub Actions 入门教程 GitHub Action 官方文档","link":"/2020/05/09/HowToUseGithubActions/"},{"title":"青岛（一）","text":"说在前面最近两个月遇到了不少的烦心事，让我颓废了好一阵子：懒得写博客，懒得跟人说话。很久没有到过海边，都要忘了在海边吹风是什么感觉了，趁着这次五一假期，和两个朋友一起去青岛玩了玩。虽然总共只待了 3 天 4 晚，但是还是有两点收获： 青岛是一个不错的城市； 不要在黄金周出游； 首先，临海的青岛让我这个南方人感受到了久违的湿润，终于不用担心因为干燥导致的皮肤瘙痒和手指倒刺，让我能够把身体乳和护手霜安心地放在行李箱里。青岛风景很美，海鲜很丰富，从视觉和味觉上都给了我满足感。 可能也是因为它的好，让大家在黄金周里都想去看看。我们 4 月 29 号晚上到时还很冷清，街道上车马稀疏，但到了 5 月 1 号立马到处都人挤人起来——我们计划中的不少的去处都是被人海给劝退的，比如信号山公园和小麦岛等等。我很讨厌人扎堆的地方，不管再好的去处，一旦人群密集起来我就会变得很焦躁。今年五一期间大家因为疫情缓和而报复性出游，让我感受到了人们的热情。所以趁着还在学校读书，假期安排比较自由，以后还是尽可能在非公共节假日出游吧。 栈桥、啤酒和皮皮虾栈桥4 月 30 号我们开始了第一天的游玩，风特别大，尤其是在海边。虽然 14 度的气温不比北京低多少，但是直观感受起来体感温度可能只有七八度，大概率是 60%的湿度导致的吧。 我们住在青岛火车站旁边的一栋高楼里，距离海边特别近，随便吃了点早餐就往海边走了。路上遇到了很多位推销旅游项目（游船、快艇、潜水等）的大叔大妈，“4 月 30 号人少半价，明天再来就不划算了”。我对这种主动推销的旅游项目不是特别感兴趣，我只想自己沿着海岸走走看看、踩踩沙滩，不想因为“今天便宜”就去坐船或者潜水。 但是旅游嘛，总是要花些冤枉钱的。他们俩很想坐游船和潜水捕捞，一起来的还是不要扫他们兴比较好，我就也买了游船的票。潜水是真的不敢去，大风低温的天气下水和冬泳没什么区别了。游览栈桥的计划就暂停了，我们坐上一辆面包车被一起送到了不远的潜水俱乐部。在他俩潜水的时间里，我就在八大峡广场周围走了走，吹吹海风，拍拍照片。下面是几张我比较喜欢的照片。 因为是刚接触摄影，对用光、构图和相机参数都没有特别深入的了解，基本都是用半自动模式靠感觉瞎拍的。但是把看到的东西好好的拍下来的仪式感也非常契合我对“记录”本身的喜爱。 他们俩从水里出来之后很长一段时间都在瑟瑟发抖，可以看出确实很冷，同时我也庆幸自己没跟着去。他们还从海底捞出来一些贝壳和海星，观感不太好就不在这里放照片了，而且到晚上它们都发臭了…收拾好后我们才开始往栈桥方向走。这时候是中午 12 点多，但是温度反而比上午 10 点更低了，沿着海边从俱乐部走到栈桥的过程中经历了急风骤雨和雨过天晴，现在想起来这也算是一种奇妙的体验了。 栈桥景区的结构挺漂亮的，拱桥长廊和末端的回澜阁一起组成了“海上如意”的形状。有很多人喂海鸥，有人把吃食放手掌上，海鸥都不过来；有人直接把吃食往空中抛，靠近的海鸥们会竞相争食。还挺有意思的。 啤酒博物馆每去到一个地方我就想去当地的博物馆。提起青岛肯定就会想起青岛啤酒，在网上看了攻略的我们在这样寒冷的天气里还是决定离开栈桥前往啤酒博物馆。我们叫了辆滴滴，但是司机偏偏不走系统推荐的稍微远一点但是不堵的路线，而是选择了走大学路。虽然行程时间比预计的多了一倍，我们却能够在车上仔细品味网红街的美，嗯我就是在吐槽这个出租车司机。 我觉得青岛啤酒博物馆建设和运营得非常好。它分成了 A/B 馆，A 馆是不收费的，视角宏大地讲述了青岛啤酒的历史和成就，B 馆里则细致地介绍了啤酒的酿造工艺，赠饮啤酒原浆，出售文创纪念品，甚至还展示了青岛啤酒的生产车间。中途和终途酒馆都可以领取啤酒，对于喜欢喝啤酒的人来说这里是个不错的去处。 晚餐从啤酒博物馆出来我们就到了台东步行街，这里整条街都是海鲜大排档。我们几个人在“晚饭吃什么”这个问题上出现了分歧，有人想回去吃，有人想就近吃，有人想在回去路上边走边看，一度有些不愉快。这时也有店家从路对面走过来招徕，拉踩其他家店，看到这个状况我们都不想在这边吃任何一家店了。 回去路上看到一家店叫做“沂水人家”，大众点评上查了一下发现评价还不错，我们就选定了这家店。不过，不知道是不小心还是有意为之，他家菜单里写的烤多宝鱼是 78 元/只，但是我们点了一只之后店家跟我们说是 78 元/斤，虽然味道还可以，但是感觉上还是比较奇怪的。除此之外，我们还点了酱猪蹄、清炒茼蒿、辣炒蛤蜊和椒盐皮皮虾，味道都还不错。尤其是椒盐皮皮虾，椒盐永远的神！火候控制得很好，香酥的、椒盐味的壳变得很有风味的同时，虾肉保持了鲜嫩的状态。在这顿饭里皮皮虾毫无疑问是 MVP。 崂山、天主教堂、五四广场和海我发现开始写之后就变得很啰嗦，总是想把看到的听到的都写下来，记录一天的行程就花了很长的时间。索性拆成两篇来写吧！","link":"/2021/05/05/JourneyToTsingTao-1/"},{"title":"青岛（二）","text":"从青岛回来之后马上就是学生节和一系列的课程、任务和作业，根本没时间和心情来写这篇博客，所以青岛（二）这一篇拖了很久…但是过了一个多月的时间很难再拾起当时的心情了，从拍下来的照片里才能记起来去过哪里有哪些好玩的地方，可以说是看图说话。反正也没人看，我直接这样随便写写就当给自己一个交代好了，不喜欢做半途而废的事情。正义虽然会迟到，但永远不会缺席。 这一篇我们主要是去了崂山、信号山公园、天主教堂、五四广场转了转。 崂山仰口海边不知道我们怎么想的，不远千里的到青岛去爬山受累，可能这就是正经的游客吧？在前往青岛的高铁上我们才开始做攻略，在马蜂窝上找了几个青岛游的攻略，都说崂山是必须要去的地方，所以我们把崂山列在我们第二天的行程当中。好巧不巧我们选了仰口区，从市区里过去要做两个小时的地铁大巴，实在是太久了。在第一天的 2 万步之后我坐完这两小时的行程时已经有一点蔫了，到了景区下车的时候热浪扑面，虽然前一天很冷，但是这天中午阳光非常充足，把前一天的凉意一扫而空。仰口景区的结构是这样的，景点的起点是在山脚，离海非常近的位置，我们先在海边玩了玩。买了风筝想在海边放，但是奈何海风太猛且方向不确定，很难让风筝飞得高远且持久。朋友都弄的鞋里都是沙子了，但就是不能让风筝飞得让自己满意——只能怪风况不佳咯。 此时已经是12点多，我们还没有吃午饭，于是灰溜溜的到周边去找地方吃饭。景点里的餐厅又贵又难吃这是我们的共识，于是我们找了一家超市，各吃了一桶方便面（实惨）并买了一些饮料和物资背在包里开始上山了。 山和海天公不作美，我们刚检票入园就下起了雨，我们撑伞走了一段时间雨才完全停。不过这也算好，这也使得景区没有特别热。仰口景区有些道观和寺庙，这些我不是特别感兴趣就不提了。随着爬的高度越来越高，视野逐渐开阔时，我的心情还是很激动的，毕竟很少看到这样的山海景，波澜壮阔、云海翻涌的场景不由的在脑海里开始放映。我们爬到一定高度后在一个亭子里拍了下面第一张照片，山、海、天交相辉映…很难形容我当时的想法。 上面的照片是随着高度的不断提升排列的，每上一定的高度都会有不同的景象，每个地方我都拍了一些，其中最后一张是在山顶拍的。 山顶风特别大。有一个景点叫做“天苑”，一块巨石被另外的石块三个点支撑着却稳稳地立了起来，很有意思。山顶的驻足点由山体本身和一些悬空的木质围栏、栈道组成，些微恐高的我站在木质栈道上有点胆战心惊的，生怕被风给吹垮了或者是被这么多人的重量给压垮。站在上面看着山麓茂密的树林和蔚蓝的海水及其上随风而动的云的阴影，体会到了在北京爬山体会不到的感觉。（毕竟在北京爬山都看不到海) 觅天洞明明可以走平坦的路，我们偏偏选了特别难走的一条。去往山顶可以走常规的楼梯和一个叫做觅天洞的地方，我们也没多想就选择走觅天洞这条路了。进“洞”之前我们看到了一些警示标语——“患心脏病或者心脑血管疾病人士请折返”，我们还纳闷这不就是一个景点至于这样警告游客吗？我们偏不信就进去了。 然而结果就是它真的和它的名字一样是一个洞，内部非常的潮湿、狭窄、黑暗。我们在其中全程蹲下来扶着墙走，遇到需要爬楼梯的地方我们也几乎是贴墙爬行，用“贴地爬行”一点也不夸张，非常狼狈。爬了二十多米的高度之后终于到了开阔一点的地方，能够看到阳光了。我至今能够想起当时大家一起“苟”的样子，除了我们几个小伙子外还有一些爷爷奶奶辈的人，我非常担心这些人群的安全。非常不推荐以后有人走这个地方：我觉得这个地方作为一个景点是不合格的，标语警示强度不足，谁能知道里面是这样一个样子呢？ 没有图，就是一个约莫一人宽的洞。非要说它给我留下什么好的印象的话，那就是或许可以当作体验一下桃花源记渔人见到“山有小口，仿佛若有光，便舍船，从口入”的经历吧。 下山下山感觉比上山还累，因为上山的时候腿脚已经很疲惫了，下山走楼梯又要不断地给膝盖压力，到山脚的时候感觉膝盖有点废了。又是两个小时的大巴地铁回到住处之后天已经黑了，随便吃了一点东西我们就休息了。 其实还按照网上的攻略指示去了一趟“劈柴院”，就是一条哪里都有的古风商业街。真的是 哪 里 都 有。一点意思都没有。 天主教堂、五四广场其实没有什么新颖的和印象深刻的东西值得一提。就放几张照片吧，从上到下依次是天主教堂里的窗户、鱼山路某咖啡馆里的大猫、奥帆中心的帆船和海。 在六月的夏天里写五月的海一篇游记拖了一个月才凭借着回忆来写属实有点不可思议，但是这一个月里有很多的课程任务、课题组和辅导员的工作需要处理。直到自己最近把课程的事情都处理完，才能闲下来写这篇博客。 我发现当我有其他非常要紧且糟心的事情需要解决的时候，我总是很难静下心来做写博客、拍照片、写闲代码这样的事情。可能我的“多线程”能力还有待提高吧，或许是我的抗压能力不太行？听过很多关于现代人时间管理方面的说法，时间是海绵里的水，挤一挤总是会有的，觉得现在看大家在朋友圈里玩得很欢乐，其实玩乐之后还是有很多事情是亟待完成的。 绝大多数的人无非都是带着脚镣跳舞，但是我带着脚镣的时候我想的不是如何跳舞，而是如何把脚镣解开。这或许是不太现实、不太成熟的想法。生活中谁能够完全把手铐脚镣解开呢？解开一个脚镣之后又会发现自己被新的、更大的脚镣锁住，如何戴着脚镣跳舞，如何把脚镣舞跳好可能是未来的我给自己的重要课题。 北京的六月特别热，让我又想起了青岛五月的海风了。","link":"/2021/06/13/JourneyToTsingTao-2/"},{"title":"小程序框架：WePY、uni-app 和 Taro","text":"在上一篇博客《聊聊微信小程序及其框架》里面立了个调研微信小程序开发框架的 flag ，这篇博客就来填这个坑——我迫不及待地想要掌握一个能够“舒适编写”小程序代码的框架。 我之前提到我最想先要了解的是 WePY 和 uni-app 这两个小程序框架，WePY 是微信官方出品的小程序框架，uni-app 是使用 Vue 开发小程序的最火的小程序框架，但是这两个框架都让我特别失望。 令人失望的 WePY 和 uni-appWePY其实最期待的应该是微信的亲儿子 WePY 吧，毕竟是官方出品，质量应该会有所保障，但是看了文档并自己安装运行之后发现还是不对胃口。原因主要有以下几个方面： 语法以 Vue 为基础但是又在 Vue 的基础上进行了一点魔改，让人产生一定程度的混乱。如果要使用类 Vue 的语法来写小程序，为什么不直接用 Vue 来写呢？ 插件支持不到位，例如 vscode 中的插件 Wepy 就是完全用 Vetur 魔改出来的，在 .wpy 文件中的提示和各项支持并不到位，会提示有各种 warning 和 error； 使用 @wepy/cli 工具创建标准模板项目之后发现并不能正常编译。 第一印象很重要，如果这个框架第一时间没有让我感觉到便利，甚至是让我觉得很麻烦，那我是绝对不会再继续在继续研究它的。到这里，WePY 的尝试就结束了。 uni-appuni-app 是由 DCloud 开发的一个小程序框架，致力于让开发者用 Vue 写一套代码编译到 10 个平台都能运行。虽然一开始对于这种为系统引入过多复杂性的框架有些抵触，但是最简单的 WePY 凉了，所以也愿意相信 uni-app 说的: 即使不跨端，uni-app 也是更好的小程序开发框架、更好的 App 跨平台框架、更方便的 H5 开发框架。不管领导安排什么样的项目，你都可以快速交付，不需要转换开发思维、不需要更改开发习惯。 知乎上也有相关的帖子，说 uni-app 比较香，写起来很省心。抱着尝试的心态看了一下 uni-app 的官方文档、用 vue-cli 安装了 DCloud 官方的项目模板尝试编译运行、下载了 HBuilderX 尝试编译运行。运行是能运行，但是效果马马虎虎，体验有点糟糕，印象大打折扣。主要的问题有以下几点： 官网文档有些混乱，非常非常非常着重的说明如何进行跨端的适配、条件编译有何注意事项等等，对于只想简单在单一平台编译运行小程序的开发者来说不够简洁； 命令行工具的表现和 HBuilderX 的不一致，大部分情况下命令行下都编译运行不了，或者是当我想引入一些如 Vant 的组件库的时候小程序就编译错误； 上一条提到的部分问题如果使用 DCloud 的官方 IDE HBuilderX 的话就可以用“导入插件”的方式解决一部分。但是体验非常非常差，简直就是道德绑架——要编译就要用我的 HBuilderX。什么？你没安装啊，那打扰了； 尝试使用官方推出的插件将使用原生微信小程序语法编写的代码转换成 vue 风格的 uni-app 代码，但是转换出来之后一团糟，根本没办法运行。 uni-app 最大的问题在于它太复杂、太希望构建自己的生态、太希望牢牢抓住开发者了。复杂的东西往往都很脆弱，经不起折腾，稍微碰一下就错误百出。它几乎是强制开发者使用他们的 HBuilderX 来进行小程序开发，这一点我无法接受，你不让我自由选择开发工具，我就可以不用你。但是这些问题也情有可原，毕竟它是 DCloud 的主要业务之一，需要给公司带来一定比例的收益。 Taro 宇宙最强的泰罗奥特曼Taro 文档阅读我一直觉得很多开发者都非常可爱，从起名上就可见一斑，比如 Taro 这个小程序跨端框架、分布式应用程序协调服务 ZooKeeper 和分布式系统基础框架 Hadoop 等。Taro 是京东的凹凸实验室推出的小程序跨端框架，和 uni-app 一样支持写一套代码编译到不同的地方。目前已经进入了 3.x 阶段，除了可以用 React/Nerv 进行开发，还支持了 Vue/Vue3。我马上看了看 Taro 的官方文档，比 uni-app 好太多了：快速开始、基础教程、进阶指南、迁移指南层层递进；官方组件库和 API 列表罗列清楚，对它们在 React 和 Vue 中的使用方法说明得很清楚；还提供了专门的“教程”模块，对于刚上手的开发者十分友好；更重要的是，它提供了一套原生的 UI 组件库 taro-ui ，甚至还照顾了 Vue 的版本推出了 taro-ui-vue。依靠这些了解，我就觉得以后就是它了，要是再有新的小程序项目，我应该会首选使用 Taro 进行开发。 尝试初始项目于是，我赶紧创建了 taro-taste 文件夹。 本来打算随便写一个 demo 小程序，又不想再单独写一套后端代码（再简单也懒得弄了），就用之前申请的一个小程序用来作为云开发的基础。用 taro 自带的 cli 工具初始化了一个微信小程序的云开发模板。用微信开发者工具打开之后，一切表现都很正常，没有什么复杂的事情，没有类似 uni-app 一样的满屏 error，云函数也能够正常调用。但是用 Vue 开发小程序有一些其他的点是需要重新适应的，例如： template 部分的基础元素只能用 view 而不能用 div； 事件名称或许不一样，如点击事件需要用 tap 而不用 click 等； 安装 taro 官方的 package 最好改用淘宝的源或者直接使用 cnpm ，不然就会出现安装失败的问题。 不过整体而言已经很满意了，对 Vue 的支持也比较全面，之后应该会真正用它来进行开发吧。 不如了解一下新东西但是有一点比较奇怪的是，在 Vue 项目模板的首页文件中，根节点 view 元素有个 className=&quot;index&quot; 的属性，这是 React 类名的写法。想到 Taro 在 3.x 版本以前只支持 React/Nerv 的情况，出现 className 这个属性应该是 3.x 版本目前还没有把对 Vue 的支持做得很完善吧。 恰好我最近在做其他项目开发的时候感觉 Vue 在代码复用、数据更新和访问方面的一些体验不是特别友好，而且组件文件规模很难控制（这应该是我的编码水平问题…），不如去学习尝试一下 React 吧。听说 Hooks 配合函数组件用起来很舒服，而且 React 完全是在写 javascript/typescript，开发起来应该会比一个文件里写 template/script/style 来回切会容易把控一点吧。 当然，它们归根到底只是开发框架而已，前端项目开发万变不离其宗，但是了解一个很酷的新东西本身就可以给我很大的动力，对吧？","link":"/2021/03/14/MiniprogramFrameworks/"},{"title":"Nginx 基础","text":"背景Nginx 读作 engine x，是一个高性能的 HTTP 和反向代理服务器，还能用作邮件代理服务器或是通用的 TCP/UDP 代理服务器。有过后端程序部署经历的同学应该会有所了解，用 Nginx 能够很方便地完成反向代理、服务静态文件、实现负载均衡、接入HTTPS协议等任务。 根据官方文档里面写到的，除了提供静态文件服务、反向代理和负载均衡等功能之外，还提供以下包括单不限于若干个方面的支持： FastCGI, uwsgi 之类服务器和反向代理服务器的缓存支持； 以域名/IP为基础的虚拟服务器、Keep-alive 和流水线链接的支持； 访问日志、错误日志的输出和格式化，带缓存的日志写机制； 3xx-5xx 错误码重定向，根据正则表达式重写URI (Rewrite)； 基于客户端地址的访问控制和函数调用； HTTP referer 的验证、支持除了 GET 外的几种 HTTP 方法： PUT/DELETE/COPY/MOVE/MKCOL； FLV/MP4 的流播放、响应限流、限制单点的并发连接数和请求数； 等等…（上面只列了我读得懂的） Nginx 的功能实在太多了，在这里全部列出来不太可能。一直以来我对 Nginx 都停留在“配置是什么，work 就行”的态度。因为这周程序部署时遇到的一点问题，上网搜了好多帖子、博客寻求解决方法那种捉襟见肘、有病乱投医的样子让我觉得很狼狈。借此为契机，决定周末看一下 Nginx 的官方文档。nginx 旧版的官网文档组织混乱，建议移步 Nginx Plus (Nginx 的商业版)官网。Nginx 和 Nginx Plus 的对比放在这里。 基本功能概况Name/IP-based Virtual serversNginx 接收到请求之后会首先决定让哪个 server 来接受这个请求。在 nginx 的配置文件中使用 server 这个指令可以定义“服务器”区域，当然最后到底是谁处理这个请求也是看 server 是如何定义的。下面是示例代码块： demo.conf1234567891011121314151617server { listen 80; server_name example.org www.example.org; ...}server { listen 80; server_name example.net www.example.net; ...}server { listen 80; server_name example.com www.example.com; ...} 这个配置文件定义了 3 个服务器，都监听了 *:80 端口。Nginx 接收到请求之后会转发给 server_name 字段与请求头中的 Host 字段相同的 server 进行处理。如果没有完全对应的 Server 那么请求会被转发到默认服务器进行处理。default_server 是 listen 指令的可选参数，如果在端口号后加上 default_server 表示这个服务器是默认服务器。如果没有任何 server 有 default_server，那配置文件中定义的第一个 server 就是默认的服务器。 对 listen 中的 IP 地址进行配置也是可行的。下面再看一个配置文件： demo2.conf1234567891011121314151617server { listen 192.168.1.1:80; server_name example.org www.example.org; ...}server { listen 192.168.1.1:80; server_name example.net www.example.net; ...}server { listen 192.168.1.2:80; server_name example.com www.example.com; ...} 这个配置文件下，Nginx 会先判断请求的 IP，再判断 server_name 字段。 Locations路径配置规则在 server 区域之中，可以定义若干个 location 区域。location 指令可以根据请求的 URI 将请求分发到不同的代理或者不同的静态文件目录中，后面提到的所有 location 配置都在 server 区域之中。 location prefix 匹配符合 prefix 前缀的 URI，如果一个请求的 URI 匹配了很多 location 的 prefix 那么请求会被分发到 prefix 定义最长的 location 块中。另外，location 指令还可以有标识符配置： location = path 表示 URI 需要准确的等于 path 才会落到这个 location 区域进行处理； location ~ regex 表示 URI 匹配相应的正则表达式。如果是 ~* 的话，是忽略大小写的； location ^~ prefix 表示这个 prefix 匹配的话，不考虑相应的正则表达式； 匹配优先级要找到最好的 location 块来匹配一个 URI，Nginx 会先匹配所有的 prefix，然后再匹配所有的正则表达式。但是 Nginx 会给正则表达式更高的优先级，除非有 ^~ 标识符。准确的匹配流程如下： 将 URI 与所有的 prefix 进行比对； 如果 = 标识符的 location 命中了，直接使用该 location 进行处理，匹配过程终止； 如果有 ^~ 标识符标识某个 prefix，则后续不用正则表达式检测这个 prefix 命中的 URI； 保存最长的匹配的 prefix； 将 URI 与所有的正则表达式进行比对； 如果 URI 匹配到某个正则表达式，立即停止比对，用这个正则表达式对应的 location 进行处理； 如果没有正则表达式匹配，用第 4 步保存的最长的 prefix 来处理。 那么根据这个流程，在配置 / 对应的处理方式时，使用 = 标识符能够提高 Nginx 的响应速度。 root, index, proxy_passroot, index, proxy_pass 是几个在 location 区域内常用的指令，这里专门查一下它们的用法。 root path 用文件系统路径来表示，表示在这个 location 中从哪个目录找静态文件来服务； index file ... 定义首页文件，按照给定顺序注意匹配，最后一个文件名可以是绝对路径； proxy_pass url 将请求转发到某个代理服务器上。 变量和改写变量在 Nginx 的配置文件中可以使用以 $ 开头的变量，和 linux 的 shell 变量相似。Nginx 预定义了很多变量如 $remote_addr 表示客户端的 IP 地址，$uri 表示目前 URI 的值。用户也可以使用 set 和 map 这两个指令在配置文件中自定义变量。 Nginx 内置的变量列表在这里可以查看：core HTTP 改写return 使用 return code [url/&quot;string&quot;] 可以给请求返回相应的状态码，或者直接以 30x 的状态码跳转到后续的 url，以 200 的状态码返回一个 string。 demoReturn.conf123456789location /wrong/url { return 404;}location /permanently/moved/url { return 301 http://www.example.com/moved/here;}location /text/url { return 200 &quot;hello world&quot;;} rewrite 使用 rewrite regex target cmd 可以将 regex 匹配的路径改写到 target，cmd 这个参数有 break 和 last 这两个最常用的。它们俩的区别有两点： last 会终止在当前 server 或者 location 区域当中的 rewrite 执行，但是重写到 target 之后落在新的 location 中的 rewrite（如果有的话）还是会继续执行； break 终止当前背景下的 rewrite 执行之外，新的 location 中的 rewrite 也不会执行。 rewrite 的例子可以看下面的配置： demoRewrite.conf123456789location /users/ { rewrite ^/users/(.*)$ /show?user=$1 break;}server { rewrite ^(/download/.*)/media/(\\w+)\\.?.*$ $1/mp3/$2.mp3 last; rewrite ^(/download/.*)/audio/(\\w+)\\.?.*$ $1/mp3/$2.ra last; return 403; # 可以组合使用} 总结这次走马观花看了一篇最基础的教程有了较多的新认识，服务静态文件、反向代理、压缩和解压缩、内容缓存等等内容在 Nginx Plus 的文档中都有比较系统的讲解，之后有需要或者有时间的时候再看看吧。","link":"/2021/08/15/NginxBasics-1/"},{"title":"打包发布 React 组件库","text":"起因「代码写了不测等于白写」我总是跟身边的朋友这样调侃。然而我们写前端项目时很难在代码层面进行测试，大部分函数都是基于事件响应，接收用户输入的参数，并对页面组件或数据产生一定副作用，Mock 起来很麻烦。所以前端项目的测试往往都是端到端测试，即模拟用户在页面上进行操作，测试路径越离奇越好，因为无法提前预知用户会如何使用，所以最好在测试时可劲儿造。 曾经还会想着用 Cypress 等自动化工具进行端到端测试，例如用代码定义【打开某页面–&gt;拖拽滑动条至页面下方–&gt;点击输入框使之获取焦点–&gt;输入“Hello world”–&gt;按下回车–&gt;等待页面响应–&gt;观察响应是否符合预期】这个过程，但只要遇到元素稍多的页面，编写测试用例的过程就会变得机械呆板。 如果组件足够小，内容够聚焦，那么测一下也不是不可以。因为想在不同的项目中复用同一套富文本编辑组件(体积比较大，且包含机器构建的JS)，我把它单独提出来作为 NPM 包发布以便各个项目安装使用。这当中编码和测试都遇到了一些问题。 打包经过目标既然要在不同项目之间共用，那该组件肯定至少已经应用到一个项目中。所以最终目标就是把项目中原先引入的组件完全替换成为 NPM 包版本的组件后，所有富文本编辑预览功能都照常。 原先组件结构CKEditorFormFields.tsx12345678910111213141516import './some-styles.css';import React from 'react';import { CKEditor } from &quot;@ckeditor/ckeditor5-react&quot;;import CustomBuildEditor from '@ckeditor/ckeditor5-custom-build'export const CKEditorInput: React.FC&lt;ControllableFormFieldProps&gt; = () =&gt; { /* * ... */ }export const CKEditorRenderer: React.FC&lt;ControllableFormFieldProps&gt; = () =&gt; { /* * ... */ } 原先的组件定义基本上如上面片段所示，其中 CustomBuildEditor 利用了 CKEditor5 的自定义构建，算是按项目需要选取必要功能构建出来的编辑器母版，它本身的使用方法很 HTML，不太适合直接用在 React 项目里，需要用 @ckeditor/ckeditor5-react 进行包装。 而这个 CustomBuildEditor 是自定义构建工具编译好之后打包好后（后续用 ckeditor-dist 称呼）下载到本地的，如果不用 NPM 包的话需要在几个项目间复制粘贴。或许因为我们项目用的是 TS，无法直接从本地目录下直接引入，所以我们用 package.json 依赖的文件链接定义了一个叫做 @ckeditor/ckeditor5-custom-build 的假包供代码引入使用，但这个方法时而奏效时而报错，或是在张三电脑上能用而李四电脑上用不了。可以确保解决问题的方法是将该 ckeditor-dist 目录复制到 node_modules 当中，但是这样过于原始。于是决定有时间研究一下 NPM 打包。 Hello-richtext目标富文本组件包名叫做 Hello-richtext，它需要依赖我们自定义构建的富文本编辑器母版，所以首先将 ckeditor-dist 单独作为一个 NPM 包发布到我们团队的私有制品库中，就起名为 ckeditor-custom-build。 把 ckeditor-custom-build 加入到依赖中，原先组件中包含的所有文件都复制到 Hello-richtext 的代码目录中。利用 tsc 以 &quot;target&quot;: &quot;ESNest&quot; 的配置将 .tsx 格式的文件编译为 .js 和 .d.ts 文件，或许这也是最终在前端项目中被应用时的引入形式。 随后利用 Jest 和 React Testing Library 写下了如下的测试用例。 render.test.jsx12345678910111213141516171819202122232425262728293031323334import React from 'react'import { render } from '@testing-library/react'import { Form } from 'antd'import { CKEditorInput, CKEditorRenderer } from '../dist/CKEditorFormFields'import '@testing-library/jest-dom'Object.defineProperty(window, 'matchMedia', { writable: true, value: jest.fn().mockImplementation((query) =&gt; ({ matches: false, media: query, onchange: null, addListener: jest.fn(), // Deprecated removeListener: jest.fn(), // Deprecated addEventListener: jest.fn(), removeEventListener: jest.fn(), dispatchEvent: jest.fn(), })),})const TestForm = () =&gt; ( &lt;Form initialValues={{ renderer: '&lt;p&gt;Hello world!&lt;/&gt;' }}&gt; &lt;Form.Item label=&quot;Mock Input&quot; name=&quot;input&quot;&gt; &lt;CKEditorInput data-testid=&quot;input-field&quot; /&gt; &lt;/Form.Item&gt; &lt;Form.Item label=&quot;Mock Renderer&quot; name=&quot;renderer&quot;&gt; &lt;CKEditorRenderer data-testid=&quot;renderer-field&quot; /&gt; &lt;/Form.Item&gt; &lt;/Form&gt;)test('test rendering', async () =&gt; { render(&lt;TestForm /&gt;).debug()}) 启动测试时遇到的问题只要富文本编辑器能够正常渲染就成功了，所以首次运行测试我比较保守，只定义了简单的表单并把自定义的两个组件作为表单项置入其中，并尝试将渲染结果用 render().debug() 的方式打印出来看看是否正确渲染。 但是启动 Jest 之后遇到了一系列问题，下面列举了我遇到的问题以及相关的解决方案。 无法解析 .jsx 格式文件，通过安装 @babel/preset-react 插件并创建 babel.config.js 应用该插件解决； 提示 ‘react’ 这个包没有导出 default，通过安装 @types/react 和 @babel/preset-env 解决，其中 babel 插件同样需要应用到配置文件中； 提示没有 window.matchMedia 方法，直接通过 Object.defineProperty 给 window 打上补丁（官方建议）； 无法解析 CKEditorFormField 中引入的 .css 文件，通过安装 identity-obj-proxy 依赖，并在 Jest 配置文件的 moduleNameMapper 属性中加入 &quot;\\\\.(css|less)$&quot;: &quot;identity-obj-proxy&quot; 解决； 稍微麻烦些的就是上面4点，当然还有一些其他的必要的依赖也是需要安装的，这里给出局部 package.json，Jest 和 Babel 的配置分别如下： package.json1234567891011121314151617181920212223242526272829303132333435{ &quot;name&quot;: &quot;Hello-richtext&quot;, &quot;version&quot;: &quot;0.0.1&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;jest&quot;, &quot;build&quot;: &quot;tsc&quot; }, &quot;keywords&quot;: [ &quot;richtext&quot; ], &quot;dependencies&quot;: { &quot;react&quot;: &quot;^17.0.0&quot;, &quot;@ckeditor/ckeditor5-react&quot;: &quot;^3.0.3&quot;, &quot;@ckeditor/ckeditor5-build-classic&quot;: &quot;^31.0.0&quot;, &quot;ckeditor5-custom-build&quot;: &quot;0.0.2&quot;, &quot;antd&quot;: &quot;^4.16.13&quot; }, &quot;devDependencies&quot;: { &quot;@babel/core&quot;: &quot;^7.17.5&quot;, &quot;@babel/preset-env&quot;: &quot;^7.16.4&quot;, &quot;@babel/preset-react&quot;: &quot;^7.16.7&quot;, &quot;@testing-library/dom&quot;: &quot;^8.11.3&quot;, &quot;@testing-library/jest-dom&quot;: &quot;^5.16.2&quot;, &quot;@testing-library/react&quot;: &quot;^12.1.4&quot;, &quot;@types/jest&quot;: &quot;^27.4.1&quot;, &quot;@types/react&quot;: &quot;^17.0.39&quot;, &quot;babel-jest&quot;: &quot;^27.5.1&quot;, &quot;identity-obj-proxy&quot;: &quot;^3.0.0&quot;, &quot;jest&quot;: &quot;^27.5.1&quot;, &quot;react-dom&quot;: &quot;^17.0.2&quot;, &quot;react-test-renderer&quot;: &quot;^17.0.2&quot;, &quot;ts-node&quot;: &quot;^10.7.0&quot;, &quot;typescript&quot;: &quot;^4.1.2&quot; }} jest.config.ts123456789export default { coverageProvider: &quot;v8&quot;, moduleNameMapper: { &quot;\\\\.(css|less)$&quot;: &quot;identity-obj-proxy&quot; }, testEnvironment: &quot;jsdom&quot;, // 其他均为默认} babel.config.js123456module.exports = { presets: [ ['@babel/preset-env', {targets: {node: 'current'}}], ['@babel/preset-react', { targets: { node: 'current' } }], ],} 测试补全解决上一节遇到的问题之后，测试脚本可以顺利运行了，需要稍微补全一下测试用例。因为 CKEditorInput 从 ckeditor-custom-build 中加载 CKEditor 时采用了异步加载，所以用 rlr 的 render() 第一时间拿到的页面源码内显示该方法仍在加载中。通过 screen.logTestingPlaygroundURL() 方法可以获取 Debug Playground 的访问链接，用浏览器打开可以看到下图的内容，清楚明了。利用它还能获取如何查询页面元素的提示。 我期望两个组件都正常渲染，如果 CKEditorInput 组件需要异步加载，那么设置等待即可。测试用例补充为下面的样子： render.test.jsx (2)1234567891011121314151617181920// 防止加载时间稍长引发 jest timeout 的问题jest.setTimeout(60000)// ...test('test rendering', async () =&gt; { render(&lt;TestForm /&gt;).debug() screen.logTestingPlaygroundURL() await waitFor(() =&gt; screen.getByText(/hello world!/i), { timeout: 30000, }) await waitFor(() =&gt; { // 根据 debug() 的返回结果发现: // 可以通过获取 &quot;段落&quot; 这个工具栏提示字样来判断是否已经渲染出富文本编辑器 screen.debug() screen.getByText(/段落/i) }, { timeout: 30000, })}) 打包、发布完成测试完成后，利用 npm publish 命令将 Hello-richtext 发布到团队的私有制品库中，完成打包流程。在两个实际项目中安装 `Hello-richtext@0.0.1` 后，组件切实可用。 这次打包发布 React “组件库”的经历给了我几点体会， 首先是学习和实践了 React 组件的测试流程，加深了自己对于前端项目测试的理解； 其次让自己构建 NPM 包的流程更规范，之前发布的几个 NPM 包因为图方便求速度都没有写测试，没测等于没写； 在目前两个可能未来更多的项目开发中事实上地提升了代码复用度和开发体验，原先富文本编辑在各个项目间维护…挺麻烦的。","link":"/2022/03/12/PublishNpmPackageOfReactComponents/"},{"title":"rFTP - 用 Rust 实现简单的 FTP Server (1)","text":"开发动机核心动力是我有学会一门系统级编程语言的梦想。所以计划用 Rust 为开发语言（手段）完成本科三年级计算机网络专业课上的 FTP 大作业（目标），学习 Rust 的同时巩固计网的基础知识。 虽然大一刚入学就开始接触 C/C++，但是对于当时没有任计算机知识何积累的我来说用这样的方式开始我的编程入门实在是颇为残忍。或许我当时连内存大小和磁盘容量都分不清，不知堆栈为何物，也搞不懂什么编译链接，让我去理解指针实在是有点为难。现在回过头来看，当时的教学顺序对零基础的学生来说是不太友好的：老师在讲指针结构的内存优化时我甚至还写不出像样的符合语法的程序，课程内容就自然也就无法很好地消化了。 如果由我来制定教学计划，我一定将最开始的编程入门课定为使用 Python 教学而不是 C/C++，在知道如何写出鲁棒、高效、优雅的代码前，先要做到能写代码，就好似学会跑步之前需要先学会走路；等学生们了解了计算机组成原理、操作系统等计算机基础知识之后（或同时），再教授 C/C++ 等较低层的、系统的编程语言了。话扯太远了，就此打住。 因为当时的无知无能，我在大学前两年的专业课学习中并没有把基础打牢，现在希望可以通过恶补计算机知识来抢救一下，而与此同时我也希望选择一门系统级语言来作为接触计算机底层的抓手，我对 C/C++ 有些 PTSD，Golang/Java 又太面向应用构建了，所以选择了社区里比较火的 Rust 来入门，可能本质上这也是一种跟风吧。 Rust 基础Rust 的所有权和生命周期机制是它很重要的亮点，同时也是难以上手的概念；Rust 拥有强大的枚举值机制，配合上全面的模式匹配，使得程序控制流和错误处理变得灵活优雅，Golang 没有枚举类型的情况有时显得捉襟见肘；另外和 C++ 不同，Rust 没有继承的概念，而是和 Golang 类似采取“组合大于继承”“组合而非继承”的方式来达到面向对象的目标，以取得更高的编码灵活度。 所有权Rust 所有权三条基本规则： 每个值都有一个所有者； 同一时间只允许存在一个所有者； 当所有者离开作用域，值会被抛弃(drop)。 离开作用域之后，变量会被释放掉(drop)；直接赋值会导致右值的所有权被剥夺；如果只希望借用变量的值，可以使用 &amp; 符号进行借用，如 &amp;var 表示变量的只读借用，而 &amp;mut var 表示变量的可写借用，同一个作用域中只允许存在一个可写借用；可写借用创建出来且仍在存活时，后续再创建的只读借用就会失效（或者编译器编译失败）。 存放在栈上的基本类型可以通过 Copy 特征自动的进行复制，而不是转移所有权。Rust 不允许在实现了 Drop 特征的类型上标注 Copy 特征，编译器会提示编译错误。也就是说 Copy 特征只复制栈上的数据。 除了完全存放于栈上的基本数据类型以外，大部分类型都是主体数据存放于堆上，索引（或者叫指针）在栈上，此时通过 Copy 只会实现指针的复制，堆上的主体数据不会有变化。这时就要借助 Clone 特征来实现堆栈上数据的完全克隆。 利用切片机制可以引用一个连续元素集合当中的部分内容，需要注意的是切片是引用，并没有值的所有权。特别地，String 类型的切片类型写作 &amp;str。 生命周期Rust 生命周期基本三条准则： Rust 编译器会给函数所有的输入变量赋予一个生命周期 如果只有一个输入变量，Rust 编译器会给输出的值赋予这个输入变量的生命周期 如果函数的参数当中有 &amp;self 或者 &amp;mut self，说明这个函数是个方法，此时会给所有的输出值赋予 &amp;self 相同生命周期，以方便编写方法函数，因为这样可以少写很多生命周期符号 结构体与特征在 Rust 中没有 class 关键字，而是不约而同地和 Golang 一样选用了 struct 结构体作为数据整合与面向对象的主要载体。通过 struct typeName {} 代码块可以定义一个结构体，通过 impl typeName {} 代码块可以为该结构体定义和实现内部的方法(methods)。在方法中定义第一个参数为 &amp;self 表示只读引用实例，如果定义为 &amp;mut self 则表示可编辑地引用实例，如果没有传入 self 参数则表示为类方法，需要用 typeName::methodName 的形式调用。 为了将多个结构体之间可能存在的共有方法进行抽象，Rust 提供了特征(trait)机制。Rust 的 trait 与 Java/Golang 当中的 interface 类似，结构体通过实现特征，在某些函数中能够当作该特征的实例变量使用，为结构体实现特征的代码片段为 impl traitName for typeName {}。值得注意的是，在定义 trait 时可以给方法提供默认实现，结构体需要把特征当中的不包含默认实现的方法全都实现才能算作实现了该特征，不能部分实现。 在入参和返回值类型中标记实现某个特征的语法如下，配合泛型一起食用口感更佳： 12345678910111213141516171819202122232425262728// 使用 impl 关键字说明特征pub fn notify(item: &amp;impl Summary) {}// 使用泛型约束pub fn notify&lt;T: Summary&gt;(item: &amp;T) {}// 多个特征的约束pub fn notify(item: &amp;(impl Summary + Display)) {}// 使用 where 关键字说明类型特征fn some_function&lt;T, U&gt;(t: &amp;T, u: &amp;U) -&gt; i32where T: Display + Clone, U: Clone + Debug,{}// 泛型结构体针对特定特征的实现struct Pair&lt;T&gt; { x: T, y: T,}impl&lt;T&gt; Pair&lt;T&gt; { fn new(x: T, y: T) -&gt; Self { Self { x, y } }}impl&lt;T: Display + PartialOrd&gt; Pair&lt;T&gt; { // some implementations} 枚举类型及模式匹配Rust 有很强的枚举类型机制，感觉是另一类的结构体，配合 match, if let 等关键字可以优雅地实现控制流和错误处理。定义枚举类型的方式和定义结构体几乎完全一致，使用枚举可以使得相同用途的类型在逻辑上和空间上两个维度上更加紧凑。从各种角度来看枚举和结构体都非常相似，我们甚至可以给枚举类型实现方法。 模式匹配主要依赖 match 和 if let 两个关键字。其中 match 和其他语言中的 switch/case 语法是类似的，只不过 Rust 要求 match 必须穷尽所有的枚举情况，即强制写出 default 分支。这也合理，以编译严格著称的 Rust 不允许潜在的不可达状态。 12345678910match dice_roll { 3 =&gt; add_fancy_hat(), 7 =&gt; remove_fancy_hat(), _ =&gt; reroll(), // 抛弃默认值}match dice_roll { 3 =&gt; add_fancy_hat(), 7 =&gt; remove_fancy_hat(), other =&gt; move_player(other), // 使用默认值} if let 是单分支、更精准的 match，如果匹配的枚举值符合预期就会进入到相应的语句块里执行相应的语句，其代码块为 if let Some(var) = some_option {}。 rFTP 开发开发计划因为自己还有课题组的开发任务，业余时间也不多，所以 rFTP 的开发计划也比较宽松随性，突出一个“重在参与”。计划迭代两期，其中第一期包括基本的 FTP 指令如： USER/PASS，指定用户名和密码登录 PORT/PASV，主动和被动模式的数据端口指定 RETR/STOR，存取文件 ABOR/QUIT，断开连接 SYST/TYPE，获取服务器信息 RNFR/RNTO，文件重命名 PWD/CWD/MKD/RMD，切换当前会话的所在目录 LIST，列出当前目录文件列表 迭代的第二期计划加入相对高级的指令： REST，断点续传 DELE，删除文件 STOU，唯一存储 APPE，追加写 ALLO，预留存储空间 I/O 多路复用本科期间用 C 写 FTP Server 时跟风使用 epoll 来达到 I/O 多路复用的效果，当时对于 I/O 多路复用处于完全不明白的状态。现在对其一知半解，也打算在 rFTP 中引入这样的机制。因为是在 macOS 上开发，尝试引入 epoll 后代码无法正常编译运行，查阅相关资料才发现 macOS 并不支持 epoll，而是单独开发维护一个文件系统事件库叫 kqueue 来实现类似的功能。 为了 rFTP 的可移植性，同时也为了省心，我自然地选择引入了 Rust 的异步运行时 Tokio 来达到 I/O 多路复用、异步编程、多线程的实现目标。目前对 Tokio 的认识还停留在上手阶段，没有做深入了解和 Benchmark，不太敢说其性能如何如何，以下是 Tokio 文档中的介绍，看起来让人安心。 A runtime for writing reliable network applications without compromising speed.Tokio is an event-driven, non-blocking I/O platform for writing asynchronous applications with the Rust programming language. At a high level, it provides a few major components: Tools for working with asynchronous tasks, including synchronization primitives and channels and timeouts, sleeps, and intervals. APIs for performing asynchronous I/O, including TCP and UDP sockets, filesystem operations, and process and signal management. A runtime for executing asynchronous code, including a task scheduler, an I/O driver backed by the operating system’s event queue (epoll, kqueue, IOCP, etc…), and a high performance timer. 一个疑难问题Rust 如何实现 TcpStream 在生产者、消费者不同的作用域之间的传输？ 预期状态：服务器 listen 进入 accept loop 之后，每次接收到一个 socket，我希望可以通过 mpsc::channel 将这个 socket 和 addr 信息传输到另外一个事件循环中进行处理，但在把 socket 传到 Task 当中时，客户端出现断连的现象，暂时还没发解决。大致的代码如下： main.rs123456789101112131415161718192021222324252627282930fn main() { let (tx, rx) = mpsc::channel(N); for i in 0..N { tokio::spawn(async move { loop { let task = rx.recv(); let mut socket = task.socket; let mut buf = vec![0u8; 1024]; loop { let n = socket.read(&amp;buf); if n == 0 { break; } // do something with buf and respond to peer socket } } }); } loop { let (socket, addr) = listener.accept(); tx.send(Task{ socket, // socket closed here // Client meet error: Connection reset by peer addr, }); }} 疑难问题的权宜解决方法经过一两天的思考，觉得跨作用域传递 socket 变量是不好的实践方式，于是将上述代码改为了下面的样子：直接在服务器监听方法当中对来到的 socket 进行读取和相应处理，不再跨作用域转移变量。 main.rs1234567891011fn main() { loop { let (mut socket, addr) = listener.accept(); tokio::spawn(async move { loop { // do something with socket and addr } }) }} 参考资料 rfc959 epoll(7) - Linux manual page Mac OS X Manual Page for kqueue(2) Kernel Queues: An Alternative to File System Events The Rust Programming Language Tokio - An Asynchronous Rust Runtime","link":"/2023/01/20/RFTP-1/"},{"title":"论文阅读: Role-Based Access Control Models, 1996","text":"摘要论文描述的方法简称RBAC，基于角色的访问控制，是目前非常主流的访问控制方法。用户（User）、角色（Role）和权限（Permission）是论文中最主要的三个概念。角色和用户组这个概念很像，但是用户组仅仅只是一个用户集合，而角色则联系着用户和权限。说到底都是为了让用户获取权限来执行相应的操作，不管是加入角色还是用户组，都只是一个中间态。 RBAC0是基础模型，是任何系统实现RBAC的最低要求。RBAC1和RBAC2都包含了RBAC0，但是分别加入了不同的特性。RBAC1加入了角色层级特性，即角色A可以通过继承角色B获取角色B拥有的权限。RBAC2加入了约束特性，控制用户对RBAC中不同资源、组件的权限。而RBAC3包括了角色层级和约束。示意图如下所示，其中基础模型RBAC0是实线部分。 文章并没有给出模型具体的实现方案，这些模型主要用作产品开发的指导准则或设计原型。 RBAC模型族RBAC0基础模型主要由用户U，角色R和权限P三个实体集组成，图表中也表示出了会话S。用户代表使用系统的每一个“人”；角色代表负责一系列职责的人群，用职业或者岗位来理解；会话是将从用户到多个角色的映射。权限需要详细说明。 权限是访问一个或多个数据对象或其他资源的许可证，权限通常是正向的，即拥有权限后可以访问对应的对象。但是有的模型把权限设计成为负向的，即获得这个权限后将无法访问对象。RBAC模型中将负向权限建模成为“约束”，后文会提及。权限的含义完全取决于系统的类别和系统的实现细节。操作系统中区分了文件、目录、设备和端口等对象的读、写和执行操作；数据库对关系、元组、属性和视图等对象的查询、更新、删除和插入操作进行了区分。 图1还展示了用户分配UA和权限分配PA关系，它们都是多对多关系。RBAC的关键就蕴藏在这两个关系当中。RBAC0中各组成部分为： U, R, P, S，分别代表用户、角色、权限和会话 PA，权限分配，权限到角色的多对多关系 UA，用户分配，用户到角色的多对多关系 user， 从一个会话映射到一个用户的函数 roles，从一个会话映射到一个角色集的函数 RBAC1RBAC1在0的基础上加入了角色层级，这个特性在现代组织管理当中显得很自然。层级高的角色继承层级低的角色的权限，如Team Leader可以访问所有项目的细节而Project Programmer只能访问所属项目。 从离散数学的角度来说，角色间的层级是偏序关系，即满足了自反性、传递性和反对称性的关系。 私有权限或私有角色通常用于控制角色继承时的权限作用域，如对进展中的为完成工作访问权限如果从低级角色直接继承到高级角色似乎不是特别合适。如Team Leader不应总是收到每一位Programmer的CI Build失败通知。 RBAC2RBAC2在0的基础上加入了约束特性，这个特性有时被称作RBAC的灵魂。约束是是一个强力的机制，可以用来打造更高水准的组织管理架构。下面是文章介绍到的一些常见约束： 互斥约束，互斥顾名思义就是用户只能获得其中一个角色身份，或者同样的权限只能赋予其中一个角色； 基数约束，一个角色最多只能拥有一定数量的成员； 先需角色约束，给用户分配角色A之前需要该用户拥有角色B的身份； 角色层级约束，没错就是RBAC1中的角色层级，它也可以被看作是一类约束。 RBAC3RBAC3就是把1和2组合起来，既有角色层级又有约束条件。 基于RBAC的管理模型上面提到RBAC模型当中所有组成部分都是由一个安全管理员直接负责，这样的情况只有在极小的系统中才有可能存在。任何稍大一些的系统都有多个安全管理员。由于RBAC的主要好处就是实现了权限的管理，那么如何让RBAC来管理RBAC本身呢？论文提出的管理模型在图4中展示，其上半部分就是之前的图1(b)部分，其下半部分是上半部的镜像，其中包含了管理角色AR和管理权限AP。权限只能授予给角色，管理权限只能授予给管理角色。 RBAC模型中的管理权限可以视作修改用户分配UA，权限分配PA和用户层级RH关系的能力。这样就可以实现用RBAC模型管理自己了。 参考文献[1] Sandhu R S, Coyne E J, Feinstein H L, et al. Role-based access control models[J]. Computer, 1996, 29(2): 38-47.","link":"/2020/05/18/ReadRBAC/"},{"title":"2022年我希望...","text":"新年的元月已然过半，但直到现在我才能说我完成了上一年的工作。我一直在追求“忙的时候闲一点，闲的时候忙一点”的从容，这一年大部分时间是保持着这个状态的，让我非常欣慰。但是真正从学生身份蜕变成“开发者”“软件工程师”（或者“社畜”？其实即使是自嘲我也不太喜欢这个词），还是有着截然不同的感受和体会的。对于2022也有着无数的憧憬。 2021上半年：课程时代尾声2021年上半年我研一，为了一年上完所有的课我这个学期仍然是课程满满的，与此同时课题组的项目也开始安排给我。在课程任务和项目进度的双重压力下，我会想着“尽快结束这样的生活节奏，争取早日回归生活的正轨”，但这个状态持续一小段时间之后我逐渐与之和解了，与其认定只用考虑学习的生活是正轨，不如接受多线程地生活才是当下社会当中每个人都需要具备的基础能力这个事实。 那么话又说回来，我认为我的多线程能力还是不错的，因为在主业之外我一直以来都或多或少地参与到学院、学校的学生工作中。在相对一板一眼的计算机知识、代码编写和需要社交活动的谈话开会、学生事务之间频繁切换也没有被我归入困扰我的事情当中。这样长期以来的“训练”让我对社交行为本身脱了敏，甚至有时还会主动发起社交活动；也让我对“同时处理很多事情”这个现象习以为常。 随着课程结课，我有了更多的时间可以投入到课题组项目里。我在课题组的工作投入在一定范围内是正反馈的：投入时间增加产出增加 –&gt; 工作产出增加 –&gt; 安排给我的工作增多 –&gt; 投入时间增加。实验室有位同学开玩笑地说我是“劳模”，每天都早早来到实验室但很晚才回寝。这个状态从暑假一直持续到现在，我自己是乐在其中了。我在课题组里承担的工作让我拥有了难以替代性，在这个过程当中我收获的知识、激励还有认可都成了我齿轮转动的润滑剂——即使有的时候这种难以替代性也带来不小的压力。这个反馈过程却有点像我高中的学习历程：认真学习带来的收获主、客观上都有助于我继续认真学习，学习换成工作也受用。我觉得这样的状态是比较难得的，我享受这一状态。我觉得我很幸运，学的专业做的工作都是自己喜欢的，所以能够一定程度上保持自驱。 2021下半年：偶然与想象喜欢记录为什么不拍照呢？我在5月入手了一台富士相机，并立马带上它去了青岛。不深挖构图角度也不用 Photoshop，光是拨动相机滚轮，摁下相机快门在任何一处拍下软糯或嶙峋的云彩，波光粼粼的海面还是叶影斑驳的片片树荫、铺满和煦光影的高矮楼房，都让我感受到极为愉悦。虽然没有太多机会到外面旅游，但在学校里面简单记录四时风景也是很好的体验。 8月开始捡起闲置已久的吉他，在琴包里放了近两年，音孔部分的琴弦竟然有些锈迹斑斑。完全从零开始学，在不懂乐理的情况下，我照着吉他入门教材学习了几个基本的和弦。弹唱的曲子从教材里比较简单的《送别》到自己感兴趣的《杀死那个石家庄人》《平凡之路》等等，也逐渐意识到自己水平有限需要加强练习。下面这张图虽然没有标识我的所有练琴记录，但可以大致体现我的练琴状态：有段时间练习比较密集，有段时间又比较松懈，指尖和食指侧的茧长了又消。以前听人说吉他很简单，可能跟“Python很简单”道理一样吧，我到目前为止我学到稍微深入一点的技巧也只有横按和泛音而已。 这半年没有课程没有作业的时间里，原本以为会枯燥乏味的生活却过得很丰富，果然生活是需要偶然与想象的。 2022的小目标2022年还剩下350天，剩余的95%时间里我希望自己可以有更多从容不迫、处变不惊的心态和能力，有“彼可取而代也”、不惧跃入人海的傲骨和锐气；对待喜欢的人要满怀热情，对待讨厌的人要爱憎分明。之前总说“想的多了，做的就少”，务虚的话简单说说就好，人不能总活在空中楼阁。给我的2022定几个务实些的小目标（排序不分先后，包括但不限于）： 每个季度至少读两本非技术类书目； 每个月至少更新一次博客，类型不限； 每两周至少看一部非所谓商业片的电影； 每周至少锻炼一次，有氧/无氧、室内/室外均可； 协助所带班级内每位同学捋清未来职业发展规划； 学习乐理，能够转换吉他谱和五线谱； 开源至少3个代码仓库，做些有意思的开发。 以上。2022来年再会。","link":"/2022/01/15/SomethingFor2022/"},{"title":"暑期的生活啊","text":"已经实习四周了，学院安排的实习期已经只剩下一周，但是直到这两天公司 Buddy 才给我安排了一个比较重要且连续的工作，让我有点左右为难：下周之后我到底还去不去呢？之前四周的工作都是延续暑假前所做，多是一些较零散、不系统的碎活儿，其实这样的安排确实容易让人觉得枯燥无味，缺乏意义和价值。“摸鱼”让我觉得内心有愧，如果要做自己的事情，为什么不回学校呢？ 一周五天上班的日子让我分外珍惜周末的两天，因为周中下班回到宿舍已经快晚上8点了。这一晚上一般就会在我是要刷题，还是要看一些资讯，还是看B站这样的纠结之中过去，第二天有点后悔，但是回来之后又重复前一天的过程。究其根本，我觉得是因为我暑假想做的事情太多了。 实习 刷题 社工 上线小程序 写诸如这篇博客的东西 学习一些奇妙有趣的东西 blabla（我觉得这个引用框好好看 暑假我也更加清晰地认识了我的本质，我对不了解的事物很难提起兴趣，但是一旦喜欢某件事物之后就会开始不断的去了解去接触，就是这样一个循环。所以，我的生活好小啊。 看到手机上给自己的警言：“想的多了，做的就少”，这是高中时期自己给自己打气用的，希望自己能够心无旁骛地做自己该做的事情。但是来到大学之后发现，没有明确的事情是那么的该做了，只有想做的事情比较明确，然而想做的事情太多，在纠结之中又会不经意掉入“想太多”的境地。给自己定一个小目标吧，8月里把心沉下来，否则这个暑假将和去年暑假一样浮躁。","link":"/2019/07/27/SummerVocation/"},{"title":"记2021年小程序大赛","text":"从本科到现在总共参加过三次微信小程序大赛，前几天刚完成赛区决赛的答辩，心想着以后应该都不想再参加了，于是想记录一下这次的参赛经历。 2018 和 20202018 阴差阳错微信小程序从 2017 年正式上线博得广大关注，在第二年 2018 年春季，微信就推出了全国高校微信小程序开发大赛，吸引了很多大学生参加，我就是其中一个。正在读大二的我报名了一位学长组织的 SRT(Student Research Training) 项目，原本的题目是要开发一款在线客服平台。然而当时已经把项目申请里面提到的客服平台提前完成了，于是我们真正做的就变成了小程序。甚至还用这个小程序参加了第一届的微信小程序大赛。 虽然做的东西和项目选题没太大关系，不记得当时具体开发的小程序有些什么功能，最后也没有拿到什么奖项（但隐约记得有证书）但通过这项目我第一次接触到了 Javascript、Vue 和微信小程序这些新东西，也认识了几位非常靠谱的队友（在之后的课程作业组队当中也延续了组队），我的收获不少，所以还是非常感谢这次项目经历的。 2020 毫无波澜第二次是在 2020 年用课题组的一个项目参加的比赛，进了华北赛区的决赛，但着实因为我们准备的不够充分而且其他队伍的作品也比较优秀，我们最终也止步于此。得到这个结果我不是特别遗憾，因为我在准备赛区答辩时就有了心理预期，所以说这次参加比赛的内心感受就是毫无波澜吧。 2021 年小程序背景如果说对第二次参加比赛的小程序我只是一知半解，那么今年参加比赛的作品我就是了如指掌。因为这是我们大三学期上《软件工程》课程时做的课程作业，它的背景是给学校艺教中心开发一套能够方便琴房管理和琴房预约的系统。 本来以为这个作业像往常那样只停留在“作业”这个层面，不会有实际使用价值。但是授课老师认为我们组做得不错，于是真正帮我们联系到了艺教中心的老师开了个会。会上艺教中心老师对我们的系统非常满意，这让我们喜出望外，但同时也给我们提了一些问题，例如还没有接入清华校内统一身份认证接口、没有接入校内支付接口等等，但我们相信后面都可以解决的。 那个学期过得很快，我们组的作品获得了 A 的评分，但是我们小程序的上线过程却不那么顺利：因为要接入校内的接口，我们需要把程序部署到校内的服务器上，之后经历了漫长的申请服务器、申请域名、申请安全扫描、申请证书、申请身份认证接口权限、申请财务接口权限等流程，期间还经历了新冠疫情爆发回不了学校的一个学期以及需求变动重新开发新模块… 功夫不负有心人，终于万事俱备申请上线了，那报名参加比赛吧。小程序名字叫做“掌上艺教”。 定位和需求分析小程序的定位掌上艺教是一个涵盖清华大学艺术教育中心琴房租赁和课程管理的一站式系统。面向三类不同的用户，他提供不同的功能。面向在校师生、教职工和居民，掌上艺教提供了校内外两种安全高效的身份认证方式，认证用户可查看琴房空闲时间、预约琴房、在线付款、查看订单和核验电子票等；面向艺教中心开课教师，除了琴房预约外，还提供课程申报、志愿填报等功能；艺教办公室老师可以使用系统的管理后台应用对琴房租赁和课程业务进行管理； 需求痛点清华大学艺教中心历史悠久，业务众多。它每年开设艺术类选修课程 160 门次，指导学生艺术团 12 支队伍共 1300 名队员的排练，同时需要管理校内众多文艺场馆。 但是艺教中心目前的业务存在信息化不足、办公效率低的问题。表现在具体的业务当中有以下两个方面： 在琴房业务中，艺教中心采用“办卡储值，打孔消费”这样比较原始的机制，容易造成浪费和卡片丢失的问题；同学们要想预约琴房只能亲自去艺教中心询问是否有空余的琴房，这样费时又费力；另外，老师如果想查询、统计和备份数据或者是进行用户管理就很难办到了。这样的局面对于老师管理琴房和同学预约使用琴房来说都非常麻烦。 在课程管理上，开课教师和办公室老师们通过邮件和微信沟通开课意向和期望志愿缺乏系统性，而且在邮件或微信往来过程中信息很容易丢失；最最要命的是，收集到课程信息后，办公室老师需要把 160 门课程的开课时间、上课地点手动地排在一张 Excel 大表里。手动操作出错的概率很高，但是一旦出错会给开课教师、艺教中心和学校教务带来很大的麻烦。下面这张图片就是手动排课时用的表格截图，当然这只是冰山一角。 我们的系统就是要解决上述的痛点。 功能介绍我们开发了掌上艺教小程序和与之配套的两个管理后台（分别对应琴房和课程业务），其中小程序的主要功能有： 身份认证：对校内外用户分别进行相应的身份认证，对接清华大学统一身份认证； 查看课程表：开课教师能够查看当前学期自己开课的课程表； 课程信息查看：开课教师能够查看自己或者其他教师所开课程的信息； 开课意向填报：开课征集期间，任课教师可以在小程序中填写开课意向和排课志愿； 排课信息确认：艺教办公室老师在后台生成排课表之后，开课教师能够查看并确认课表是否符合预期； 琴房浏览：使用掌上艺教能查看艺教中心对外开放租赁的琴房列表并查看它们的信息如空闲时间、租赁单价、位置简介等； 支付定金：预订琴房后可在线支付定金，完成支付后将获取订单核验二维码； 代金券折扣：支付定金时可使用代金券抵扣指定额度的琴房定金； 电子票核验：琴房入检人员可以扫描支付完成的订单二维码核验信息并准入。 课程管理后台的主要功能有： 课程信息管理：可以对系统内课程信息进行增删改查，包括但不限于某一学期内开课教师所创建的课程； 教学场地资源管理：可在系统中维护教学场地包括教室地点、教室容量、教室属性等在内的信息； 排课表生成与调整：开课教师提交完成排课志愿后，系统将根据开课教师的志愿信息和在系统中设置的权重策略，对所有课程进行自动编排。自动生成出的课表可以进行手动调整； 后台账号管理：可以对人员进行账号管理，包括启用/禁用账号、账号密码重置及权限管理； 教师名单维护：通过维护教师名单可控制哪些用户能够使用排课系统； 通知公告：在管理后台可使用富文本编辑器编辑发布通知公告，并查看教师们的阅览情况（已读或者未读）。 琴房管理后台的主要功能有： 琴房信息维护：可以对琴房列表和琴房信息进行维护，包括琴房名称、位置、头图和占用规则（规律性占用）等； 订单管理：可以通过姓名、手机号、证件号、预约时间段、预约琴房等条件进行订单查询与统计，并查看或修改订单详情； 用户管理：可通过姓名、手机号、证件号等字段查询用户详情，进入用户详情可将用户纳入黑名单、查看用户的订单和代金券等； 用户组管理：通过设置用户组对琴房的预约权限、租赁单价和用户列表，可以实现用户的权限管理和租赁单价管理； 代金券管理：可向指定用户手动发放代金券或向指定用户组周期性发放代金券用于琴房定金抵扣。 系统架构 系统架构方面，我们选用了 Vue.js 作为 Web 应用的开发框架，小程序则使用微信原生框架进行开发。前后端通讯方面我们使用的是 GraphQL（可能需要科学上网），这和传统的 RESTful API 相比有很多优点，在这里就不展开说了。后端则借鉴了流行的微服务架构的思想，把两部分后端服务进行了实现和部署上的拆分（可以看到两个后端服务的开发语言都不一样），同时两个服务都采取了容器化的部署方式，极大地降低了开发和运维成本，同时减少了系统整体不可用的风险。 后端服务拆分实现部署的开发方式我们还是第一次采用，这确实给我们的系统带来了很高的灵活性，技术栈的选择也更加自由。而且，通过实现服务间通信，各个实体之间的交流更加密切，可以做到更多有趣的事情。例如微信小程序用户的登录状态存在一个服务 A 上，当另一个服务 B 也需要用到该状态时，可以通过直接向 A 发请求拿到相应的信息。在我们的系统当中，服务间通信是直接发 HTTP 请求，以前实习时做的系统用的是 gRPC 和 protobuf 来完成的。不过本质都差不多。 比赛结果赛区决赛当天晚上其实就已经出结果了，我们的小程序是华北赛区第 5 名，是三次比赛当中名次最高的了。虽然可能进不了全国决赛，但是我还是能够接受这个名次的。前几名的作品确实有着非常好的产品定位（例如第 2 名“帮你学拼音打字”目标是帮助中老年人学习使用手机拼音打字）和非常高的完成度（例如第 1 名“方仔照相馆”），我们的小程序作为一款在校内使用的半开放式小程序，格局比起他们的来说还是小了不少。 最后的感想2021 年的微信小程序大赛其实已经稍见颓势，从取消微信小游戏赛道这方面就能看出微信不太重视这场比赛了。参赛作品的多样性和创新性也随着时间的推移逐渐降低，越来越难以见到让人眼前一亮的好的作品。所以比赛不再受重视也不奇怪，微信一开始推出这个比赛就是想借助有热情有活力的大学生群体带动小程序的市场，而到了 2019~2020 年微信小程序其实已经占据市场主导地位，不再需要依靠比赛来扩大影响力了。 另外比赛的风气也不太好，2020 年的华北赛区决赛好像就出现了相互举报的状况，有点无语也有点无聊。不知道明年这个比赛还会不会办下去，不过就算继续办我也不太想再参与：我的热情被小程序开发消磨掉不少，也没有太多创新的点子想付诸小程序开发。小程序对于用户来说有着很不错的体验，但是对于我们开发者来说小程序是处处受限的前端应用，这也不能用那也不行。没错现在我已经不想“用户至上”了，我想做更纯粹一些的开发。","link":"/2021/07/20/TheThirdMiniprogramCompetition/"},{"title":"如何相对优雅地使用 GraphQL","text":"关于 GraphQL，它的官网(需要科学上网)是这样介绍的： GraphQL 既是一种用于 API 的查询语言也是一个满足你数据查询的运行时。 GraphQL 对你的 API 中的数据提供了一套易于理解的完整描述，使得客户端能够准确地获得它需要的数据，而且没有任何冗余，也让 API 更容易地随着时间推移而演进，还能用于构建强大的开发者工具。 作为 RESTful API 的竞品，GraphQL 从开源之初就备受关注，一是因为它是由 Facebook 开源的项目，二是它挑战了 RESTful API 的地位，这是很关键的一点。RESTful API 利用 URI 的具体内容和请求方法来区分请求的资源或者方法，其中的资源 URI 容易与路由路径产生混淆和重复；资源数量达到一定的数目之后，如何给资源 URI 起名或许也是一件困难的事情。而 GraphQL 则鼓励开发者将所有需要请求的信息显式的写在请求体当中，精确到具体的字段，不多也不少。 我参与的几个项目都是用 GraphQL 作为 API 的基础，我总结出了一个在前端相对优雅地使用 GraphQL 的方法。这篇博客不讨论 GraphQL 的基本概念，主要介绍这个方法。（为省篇幅，这篇博客里面的代码均不做异常处理） GraphQL 的原始用法GraphQL 在前端的表现其实并不新奇：根据定义好的 schema，前端用 post 请求将 query string 和可选的 variables 包装在 body 当中传给后端的某个节点，后端正确响应之后以前端查询的结构将数据返回。 利用基础方法那么根据这个基础我们就能够想到在代码中的用法了，首先在 api.js 中定义一个请求的基础方法： api/index.js1234567891011121314export async function graphql(q, vars) { const resp = await $axios({ method: 'post', url: BASE_URL + '/api/graphql', data: { query: q, variables: vars, }, headers: { token: getYourToken(), }, }) return resp.data.data} 然后在所有需要请求的地方使用这个基础方法就可以完成 graphql 的请求，可以直接把请求参数嵌在具体的请求方法里面，也可以使用 variables 的方法（但这样会需要在字符串中多写些变量定义）。 index.js1234567891011121314151617181920212223import { graphql } from './api'async function getPerson1() { const resp = await graphql( `query { person(id: ${id}) { id name address age gender mobile } }` )}async function getPerson2() { const resp = await graphql( `query ($id: ID!) { person(id: $id) { id name address age gender mobile } }`, { id } )} 体验糟糕的查询字符串或许你觉得上面的方法还可以接受，但是如果变量中存在数组、枚举值和布尔值时，直接在 query string 中插入变量的体验就会变的很糟糕。像下面这样，我这辈子都不再想见到这样的写法。 index.js12345678async function heyGuys() { const guys = ['alice', 'bob', 'carol', 'dave'] const resp = await graphql(` query { heyGuys(guys: [${guys.map((n) =&gt; '&quot;' + n + '&quot;').join(',')}]) } `)} 统一管理查询字符串在逻辑代码中写大量的 query string 不太利于维护，为此可以将所有字符串分类整理好统一管理。例如放在某个 documents.js 文件内，其他地方需要请求的时候直接从该文件导入即可。这样可以在真正的业务逻辑中避免大量的字符串。 api/documents.js1234567export const getPersonDoc = ` query ($id: ID!) { person(id: $id) { id name address age gender mobile } }` 问题仍然存在上面统一管理查询字符串的体验还凑合，但是真正开发起来就会发现有以下几个问题绕不开： 我如何知道一个字符串对应的变量应该是什么？只能查看字符串本身的定义； 我写字符串的时候如何获得代码提示呢？还是说我只能对着后端的 schema 逐字段慢慢写呢？ 既然都统一管理了查询字符串，是不是还得再封装一层查询方法呢？这样业务逻辑处的代码还能更省。 如果都用字符串如何使用 Fragment 呢？（或许可以看一下 graphql-tag） 更好的方法：代码生成如果完成一个请求需要先写查询字符串，再封装一个关于这个查询字符串的请求方法，开发效率不会很高。可以看到上面的代码很多都是琐碎且平凡的，既然如此，可以尝试生成代码。为此我们需要了解以下的包或者插件： @graphql-codegen: graphql 代码生成器，一个 npm 包。通过定义的 schema 和 operation 生成包含请求方法的 typescript 文件； GraphQL: vscode 插件，用作写 .graphql 文件时的自动补全； 配置 @graphql-codegen按照该包官方文档的指示进行安装配置即可，不需要太多的配置。其官网上还有下图所示的 live example，非常容易弄懂。 我在开发中一般会配置两个代码生成配置文件，一个用于同步后端、生成代码补全所依赖的 schema 文件，一个用于生成 operation 对应的请求方法。如下是两个配置文件的大致内容。 schema.codegen.yml12345generates: ./graphql/schema.graphql: schema: 'BASE_URL/api/graphql' plugins: - schema-ast operation.codegen.yml12345678generates: ./api/demo.ts: documents: './graphql/operations.graphql' schema: 'BASE_URL/api/graphql' # 或者直接使用 './graphql/schema.graphql' plugins: - typescript - typescript-operations - typescript-graphql-request 配置文件中的 plugins 配置项是关键。schema.codegen.yml 中的 schema-ast 是生成 schema 的 graphql 文件；operation.codegen.yml 中的 typescript-* 则是生成请求方法所依赖的插件。我这里给出的是使用 graphql-request 的例子，graphql-request 是一个轻量、简洁，支持 ts 和 promise-based API 的 GraphQL 客户端，在前后端都能使用。 生成请求方法所依赖的插件根据项目特点选定，例如 graphql-request 这个插件我用在 Vue2.x 的项目当中，而在 React 的项目中我是用的插件是 React-Query Hooks。每个插件对应的基础库的特点不一样，生成的代码风格也不尽相同，根据需要灵活选择即可。 编写 operationsoperations 顾名思义就是操作，在 GraphQL 里面操作分为 query 和 mutation，编写具名操作会被 @graphql-codegen 转换成为请求方法。下面给一个例子： schema.graphql1234567891011121314151617181920212223enum Gender { Female Male}type Person { id: ID! name: String! address: String! age: Int! gender: Gender! mobile: String!}type Query { persons: [Person!]! person(id: ID!): Person}type Mutation { setPersonGender(id: ID!, gender: Gender!): Boolean greet(id: ID!): String!} operations.graphql1234567891011121314151617181920query getPersons { persons { id name }}query getPerson($id: ID!) { person(id: $id) { id name address age gender mobile }}mutation sayHello($id: ID!) { greet(id: $id)} 因为用了 vscode 的插件 GraphQL，所以在写 operations 的时候其实是有代码补全的，开发体验比较好，下图是在 vscode 上的代码补全，在 jetBrains 的 IDE 上面的代码自动补全应该会更完善。 生成 typescript 代码写完上面的 schema 和 operations 之后，运行 graphql-codegen --config operations.codegen.yml 即在 ./api 目录下可生成一个 demo.ts 文件。其中包含了下面这样的代码： api/demo.ts123456789101112131415161718// ... 省略了很多const defaultWrapper: SdkFunctionWrapper = (action, _operationName) =&gt; action();export function getSdk(client: GraphQLClient, withWrapper: SdkFunctionWrapper = defaultWrapper) { return { getPersons(variables?: GetPersonsQueryVariables, requestHeaders?: Dom.RequestInit[&quot;headers&quot;]): Promise&lt;GetPersonsQuery&gt; { return withWrapper((wrappedRequestHeaders) =&gt; client.request&lt;GetPersonsQuery&gt;(GetPersonsDocument, variables, {...requestHeaders, ...wrappedRequestHeaders}), 'getPersons'); }, getPerson(variables: GetPersonQueryVariables, requestHeaders?: Dom.RequestInit[&quot;headers&quot;]): Promise&lt;GetPersonQuery&gt; { return withWrapper((wrappedRequestHeaders) =&gt; client.request&lt;GetPersonQuery&gt;(GetPersonDocument, variables, {...requestHeaders, ...wrappedRequestHeaders}), 'getPerson'); }, sayHello(variables: SayHelloMutationVariables, requestHeaders?: Dom.RequestInit[&quot;headers&quot;]): Promise&lt;SayHelloMutation&gt; { return withWrapper((wrappedRequestHeaders) =&gt; client.request&lt;SayHelloMutation&gt;(SayHelloDocument, variables, {...requestHeaders, ...wrappedRequestHeaders}), 'sayHello'); } };}export type Sdk = ReturnType&lt;typeof getSdk&gt;; 可以看到 getSdk 这个函数会返回一个对象，其中包含了刚刚在在 operations.graphql 中定义的几个操作。这样就从类型上锁定了这个方法的名字、参数以及返回值。这对于项目维护和开发来说无疑都是利好的。 使用生成的代码因为真正使用的请求方法肯定是要鉴权的，我们需要再调整一下生成的代码，看到上面 demo.ts 中的 defaultWrapper 函数了吗？我们只需要在调用 getSdk 时传入自定义的 Wrapper 即可。下面给个例子： api/index.ts123456789import { getSdk as getDemoSdk } from './demo'const getClientOptions = () =&gt; { return {}}const apiWrapper = async &lt;T&gt;(action: (headers?: Record&lt;string, string&gt;) =&gt; Promise&lt;T&gt;) =&gt; { const headers = { 'token': getYourToken() } return await action(headers)}export const demoClient = getDemoSdk(new GraphQLClient('/api/graphql', getClientOptions()), apiWrapper) 在需要用到的地方只需要导入 demoClient 即可，我们再用几行代码重写一遍上面的 getPerson 函数： index.js1234import { demoClient } from './api'async function getPerson3() { const resp = await demoClient.getPerson({ id })}","link":"/2021/07/23/UseGraphQLElegantly/"},{"title":"从 Vue 到 React —— 第一印象","text":"学习 React 的初衷之前说过想要学习 React，秉持着边学边记录的想法，我随即开启了这篇帖子。 从 Vue 说起我是一个 Vue 的忠实粉丝，虽然没有全部读过 Vue 的源码，但是对它的基本实现原理和大体的使用方法还是比较熟悉的。我自己思考过，我觉得我喜欢 Vue 大概率是因为我最早接触的前端开发框架就是 Vue。记得是 2018 年参加一项 SRT 的时候，为了开发一款简单的后台管理系统，我开始学习 javascript 以及 Vue。 当时我还是第一次接触脚本语言，对没错，我接触 javascript 比接触 python 更早一些。熟悉了 C/C++ 的继承机制之后，突然要接受 javascript 的原型链继承一时间有点缓不过来。但是后来还是被磨平了棱角，被迫接受了原型这一设计。为了开发 Web 应用通过一位学长的介绍接触到了 Vue 这个框架。我直接惊为天人，还能这样写？因为根据我更早之前的一些浅显的印象，Web 开发是分别要编写 HTML，javascript 和 CSS 三种文件的。现在用 Vue 一个文件就可以生成一个完好的页面，着实非常酷炫。也是在 Vue 这里，我了解到了组件、生命周期、全局状态管理、前端路由等等一些重要的概念，所以先入为主地对 Vue 有强烈好感也正常吧。 Vue 的好处就不说了，这里主要想说以下我遇到的问题： 在写 Nuxt 项目写到功能比较重的组件时，一个组件 Vue 文件代码可能会到 800 ~ 900 行，写完 template 后滑滚轮滑到 script 部分找到 methods 里对应的地方写函数，如果模板部分出问题了还得滑回去。文件行数一旦长了，这个上下滑动找代码块的过程真的有点难受，一旦思考过程中出现一小段的空挡，那么就有可能导致思绪完全断掉。 另外，Vue 的代码复用方案我觉得不是特别好：模板方面的槽和脚本方面的混入这两个我觉得不是特别优雅，尤其是混入。混入的文件一旦多了可能会造成组件难以维护的问题，例如不知道模板中使用的某个属性到底是 mixin 中来的还是从 data 或者 props 中来的，如果出现覆盖那么覆盖规则、覆盖后的值又是什么。 插件支持我觉得也没有做得特别好，虽然 Vetur 已经做到相当好了，但有一些情况仍旧是解决不了的，比如上面说的 mixin，其中的属性或者方法就没有办法在调用的页面当中提供补全提醒。 最后，因为总是遇到一些不可名状的 Bug，我打算以后项目的开发要用 typescript，但是 Vue 对 typescript 的支持不是特别好（听说 Vue 3.x 版本有所改善，但是看了一下 Vue3 的文档觉得 composition API 和 React 实在是太像了，不是特别感冒），所以有些打退堂鼓。 总的来说，Vue 的问题不是特别大，我也没有在做很大型很复杂的项目，上面说的小瑕疵不是本质问题（有问题应该也是我自己能力还没到位）。但是总让我觉得有可以更好的地方。 React 哪里吸引我React 是 Facebook 推出的用于构建用户界面的 Javascript 库，应该是目前最热门的“前端框架”，加上引号是因为我觉得它其实不算是一个框架，只是一个“库”，扩展了 js/ts 的语法特性，使它们可以更方便地写 Web 应用。 它很火，看着也很酷，更原汁原味，更轻量化，更自由，有更多的可能性，这应该就是我想了解它的原因吧。 对 React 的第一印象读了一下官方的入门教程，React 给我印象最深的有下面几个方面： 完全使用 js/ts 编写，没有增加新的文件类型，在 vscode 中编码体验良好（jsx/tsx 不太算新类型吧）； state 与普通属性区别开来，如果需要更新需要显式的调用 setState 方法，虽然牺牲了一定的灵活性，但是也一定程度上促进了数据的安全访问；同时，这样近于“严苛”的 state 更改方法会鼓励开发者将组件拆分成更小的部分； 提供函数组件和类组件两种写法，函数组件的写法可以省很多空间； React Hooks 看起来像是 Vue Composition API 的原型，函数组件用起来会比较“优雅”； JSX 渲染函数的写法可以将实现某功能项的代码尽可能的收缩到同一个空间区域，拥有更好的空间“局部性”，免于在 template 和 script 之间来回切换打断思路的困扰； 阿里的 Ant Design 为 React 前端开发提供了一个很好的组件库和设计规范，不得不说，阿里对优化用户体验真的有很深入的研究。 之后探索的方向但是其实前端框架归根结底做的事情都是一样的，是让开发者能够较为轻松地开发出易于测试、易于维护、方便拓展、体验良好的跨平台的 Web 应用。不管是之前写 Vue 代码还是之后要写的 React 的代码，都是为了这样一个同样的目的。然而如果仅仅光想着实现功能而不去思考更多，很容易陷入为写代码而写代码的陷阱当中。 因为我在实验室课题组里负责了几个项目，几乎每个项目都是不超过3人的小团队。如果开发周期稍微变长一些，项目的功能就会变得异常复杂，而作为开发者，在测试的时候很容易就会局限在正常（或者说正确的）业务逻辑当中，不会发现一些匪夷所思的问题。（感觉真的很难让一个要写正确逻辑业务代码的开发者去做一些极不符合预期的事情。）测试很重要。只要不是自己小打小闹的学习性质地写着玩儿，测试就是极其重要的。测试保障的是软件的质量，在任何有甲方的项目当中，没有进行详尽测试都是不负责的。在写后端代码的时候，测试起来比较容易，因为提供的 API 是可预期的，传入什么样的参数，返回什么样的响应，都是清清楚楚的。至少对于开发者自己来说，后端代码都是白盒，将单元测试覆盖率提高就可以显著地提高代码的可靠程度。那么前端测试呢？ 前端测试中主要有单元测试、组件测试和端到端测试。单元测试其实并不区分写的是前端还是后端的代码，都是追求更高的代码覆盖率。而组件测试和端到端测试可能对于前端应用来说更重要吧，因为前端应用给用户操作的组合是无限的，用户可以选择以任何路径，触发页面任何元素可能的动作，想要详尽地测试属实比较困难，但是组件测试和端到端测试应该都是比较成熟的测试方案，能够在一定程度上提高应用的可靠程度。 之后除了继续接触 React 之外，我还会去了解一些组件测试和端到端测试的最佳实践，扩充一下自己的前端知识储备。","link":"/2021/03/27/Vue2React-1/"},{"title":"聊聊微信小程序及其框架","text":"为什么是微信小程序微信很早就有一套专用的JS-SDK在微信客户端上面使用，其开放了录音、二维码、地图、支付等几十个 API，能够支持微信服务号的运转，当时大部分支付、扫码等功能的对接方都是这样的服务号。但是在 2016 年 1 月 11 日微信之父张小龙表示服务号还不够优秀，微信正在研究一个新的服务形态，起名叫做“微信小程序”。在 2017 年 1 月 9 日，第一批微信小程序低调上线，而选择这一天也是为了向 iPhone 1 代的发布致敬。 很快，微信小程序依靠微信的庞大用户量迅速的占领了市场，其他各个大厂见势相继效仿，但是从目前来看它们都很难和微信小程序再抗衡了——不管是用户数量还是开发者数量。这倒也不太奇怪，这种行业往往都是快鱼吃慢鱼不是大鱼吃小鱼，emmm…不过背靠腾讯的微信也不能说是小鱼吧。 为什么要写微信小程序首先想说的是，微信小程序的生态是比较混乱的，开发起来有一点难受，有不少情绪比较激动的开发者直接说微信小程序就是“s**t”，我也能够理解其中的一大部分感情。 我从大二参加微信举办的第一届大学生微信小程序大赛到现在已经有 3 年了，这期间虽然不是一直在开发小程序，但是每年都会或多或少因为课程或者是项目的原因接触小程序开发，所以对微信小程序还是有一定的了解的。 小程序非常不好写。我觉得有以下几个方面的原因: 一个页面(Page)拆成四个文件这样分散的组织形式让我觉得有点难受，有的人可能会说这是关注点分离，但是我觉得 Vue 在单文件内拆成多个部分的形式可能更好一点，一个重要的事情值得注意，关注点分离不等于文件类型分离。而且你说一个叫做page的页面，它下面的四个文件名是叫page.wxml好还是叫index.html好呢？ 微信开发者工具非常不好用，首先它很占内存，内存小的机器上运行微信开发者工具一段时间后会出现奇奇怪怪的问题，因为遇到的次数有点多也没有特别记得，在这里也说不出来了。 因为在微信的生态里面，处处都要依照微信的规矩来进行开发或者运维（这倒也没办法），用某某接口需要是某某类目的小程序，需要有某某资质的主体等等……申请接口、申请上线等种种流程都十分繁琐。 官方文档有些混乱，而且最近两三年内没有进行过较大的更新改进。 但是有的时候又不得不写它，因为它对用户更加友好。如果换作是我的话，我也不会为了去餐厅点餐或者是在奶茶店买奶茶专门下载一个 App，为了扫健康码就更不会。微信小程序就是为了替代微信服务号这样的“用完就关”的应用场景的，开发的时候把它当作微信服务号 2.0 来开发就好了，不要提高自己的心理预期以为自己是在开发一款 App。这样想的话，开发起来就会好接受多了。 小程序框架浅析逻辑层和渲染层 微信小程序通过微信客户端(Native)这一桥梁向外界服务器发送请求和接受响应、调用手机本地接口(拍照、上传文件等)。小程序分为了渲染层和逻辑层，小程序页面的 WXSS、WXS 和 WXML 运行在渲染层，而 JS 运行在逻辑层。WXS 是专门给小程序推出的一个脚本语言，是 JS 的子集，运行在渲染层执行一些简单的数据处理任务，据官方文档说使用 WXS 在 Android 上没有太多性能提升，但是在 iOS 上用其执行相关任务能加速 2~20 倍。 微信小程序的渲染层与逻辑层也通过 Native 进行通信，比如渲染层将触发的事件传输到逻辑层，逻辑层将更新的数据传输到渲染层等等。可以看到上面这张图里渲染层分了很多个 Webview，其中每个 Webview 都代表了一个小程序页面。 WXML 文件其实是标识了页面的元素及其相互关系，在微信小程序的编译过程中，WXML 文件会被编译成为 JS 对象用来在渲染层维护一个虚拟的 DOM 树。通过与逻辑层的数据进行组合，形成一个数据和结构都完整的虚拟 DOM 树用以渲染。每次在逻辑层调用 setData 方法时，逻辑层都会将这个消息传输到渲染层，渲染层通过对比发来的数据与之前的数据，将有差异的数据应用到 DOM 树上，从而进行更新渲染。 目前市面上有许多的小程序开发框架，如 Taro、Uni-App、mpvue、WePY 等，有实验显示使用小程序框架进行开发会使得小程序性能提升，其中很大一部分原因就是开发框架会对 setData 的调用进行优化，减少逻辑层和渲染层的实际通讯次数，从而提升性能。 而采用渲染层和逻辑层的架构主要是为了阻断页面渲染和逻辑处理，从而加强监管、提升性能。 小程序页面生命周期 从微信小程序官方文档上面的生命周期图示(方便起见，我把纵向的长图拆成了左右两个部分)可以看得很清楚，逻辑层与渲染层分别进行初始化。 逻辑层执行完 onLoad 和 onShow 两个生命周期函数之后，等待渲染层初始化完成的通知； 逻辑层收到通知之后，将初始数据传输给渲染层，渲染层拿到数据进行首次渲染之后再次通知逻辑层，让其执行 onReady 生命周期函数； 执行完 onReady 函数之后，小程序就处在 Active 状态了； 如果小程序在激活状态下被最小化到微信的后台或从后台被唤起，则会调用 onHide 和 onShow，如果在激活状态被关闭，则会调用 onUnload (一般不会用到)。 小程序从后台被唤起时的启动叫做热启动，第一次打开或者距离上一次打开已经过去了足够长的时间时叫做冷启动。他们进入页面生命周期的位置不同，开发的时候需要格外注意一下。 我自己的小程序开发方法开发微信小程序有许许多多的方式，最原始质朴的方式就是直接使用微信开发者工具进行编码和调试，这是我在大二的时候使用的方法。我已经很久没有用过这种方法了，但是它至今仍然给我很不好的回忆，究其根本主要是因为 IDE 实在是太难用了。 后来使用 WebStorm 来进行微信小程序编码，但是发现我自己的笔记本电脑(18 年老电脑了)同时带 WebStorm 和微信开发者工具两个“重型” IDE 实在是有点吃不消，遂作罢。 后来接触到了 gulp 这个前端工程化工具，可以让编码过程更加自由，尤其是能够使用 sass 等 css 预处理器，让我觉得开发起来清爽了很多。目前我是用VS Code进行编码，同时使用了minapp, Live Sass Compiler这两个插件，能够原地使用 sass，也没有增加过多的复杂性，很符合我自己的“编码哲学”hhhh。 我在写代码的时候一直觉得奥卡姆剃刀原理是真理，可以不要的就一定不要。这样的想法使得我在之前的开发中从没有想过用小程序开发框架，“一次编码自动构建多个平台的小程序”，我需要开发的只有“微信小程序”这一个而已，不需要增加那么多的复杂性。 但是最近越来越受不了小程序复杂的设计了，尤其是写惯了 Vue 再来写小程序，简直就和降智了似的。 之后我应该会看一些小程序框架的文档，先从 Uni-App 和 WePY 这两个开始吧。Uni-App 是用 Vue 语法开发小程序的框架，支持一键生成多端小程序。而 WePY 则是微信官方推出的小程序开发框架，仅支持微信小程序。这也算是立了 flag 吧。","link":"/2021/01/21/WechatMiniprogram/"},{"title":"当我写H5时，我到底在写什么？","text":"背景“活动宣传写个H5就可以了”，”学生节不如做一个H5小游戏吧，比如之前那种学堂路躲避乌鸦“……在这几年的学习和生活中我听到过很多次H5，也真正看到过、使用过、制作过H5，但是我对H5这一个词的真正定义还是不太了解。它给我的直观印象就是在手机上运行的、包含许多动画甚至音乐的纯前端/弱后端页面，最常见于微信群、公众号和朋友圈，或许这也是大多数人对其的印象。对自己接触的东西一点也不了解是不能接受的，所以要简单调查调查。 H5的由来几种定义 h5是HTML的第5级标题标签； H5是在手机上运行的、包含许多动画甚至音乐的纯前端/弱后端页面； h5是2014年10月由W3C制定的HTML新一代标准，其中包含了新标签、新属性、多媒体和本地存储等特性。 H5为什么火？H5是HTML的第5代标准，它不是一个新的应用，不是一个编程语言，甚至不是一个实体(Web应用、微信小程序等)，他就是常规意义上的HTML新版本，和C++17、C++20差不多。HTML等Web应用相关语言和Golang、C++等语言还不一样，它们的标准还需要各大浏览器的运行时支持才算是“真正”拥有了新特性。但是如今大多数用户都能够很方便地通过电脑、手机接触到Web应用，其中不乏动画酷炫、插画精美、音乐好听、让人眼前一亮的应用，开始有人将这样的应用叫做H5，后来逐渐传开再也无法很好地定义了。 普通用户是不会去了解H5到底是什么的，隔行如隔山，弄明白这个对用户来说作用不大。据我观察，各大H5应用模板网站也不会强调这个H5到底是怎么做的，而是统一作为模板打包卖给用户就行。H5可能是纯前端的，也有可能有弱后端，但是“注重呈现”应该是H5的核心，有“动态海报”内味儿。接下俩的H5统一取第二个定义。 H5的组成 H5也是Web应用，那么就离不开HTML、CSS和JavaScript，HTML负责文档结构、CSS负责视觉样式、JS负责业务逻辑，在写H5的时候其实是在写这三种语言。HTML5中的如&lt;canvas&gt;、&lt;audio&gt;、&lt;video&gt;和&lt;svg&gt;等新标签确实为前端的图形渲染提供了良好的载体，但是应用的代码组织与以前差别并不是很大。如今许多浏览器都支持HTML5标准，许多前端程序员也在使用HTML5标准提供的新标签，那么可以说现在只要是写前端都是在写H5。 SPA - 高级H5单页面应用(Single Page Application)的说法最近几年非常流行，前后端分离的开发风格、Web技术和云计算的发展使得浏览器中运行的Web应用无论是开发流程还是使用体验上都越来越接近原生应用(Native Application)。许多SPA的功能全体量大，不输给原生应用。HTML5中提供的本地存储(localStorage)特性相信许多开发者都用过，使用它可以构建相当强大的功能。那么把它叫做高级H5也不过分吧？（doge 另外，如Vuejs、Reactjs等在内的前端开发框架也简化了SPA的开发。 我以前接触过Vuejs和微信小程序，当时觉得微信小程序是大部分借鉴了Vuejs的精髓。前一阵子又看了看Reactjs的文档，发现微信小程序的架构里也能发现Reactjs的影子……虽然React有facebook官方的支持，但是有一说一它的中文文档是真的不行，过时的文档google出来结果竟然还在前列。相比之下Vue虽然没有大公司支持，但是越来越赢得开发者的青睐，其文档的完善也是一大因素吧。 Vue.js: The Documentary最后放上Vue.js的纪录片，赏心悦目。","link":"/2020/06/07/WhatIsH5/"},{"title":"用两年读完《白鹿原》","text":"陈忠实先生花了六年时间著出《白鹿原》这部巨作，而我却前前后用了近两年时间才读完这部作品，实在惭愧。因为用的是“微信读书”读的电子书，阅读记录都有存储在其平台上，才能得知我原来在 2022 年看完《杀死一只知更鸟》之后就开启了《白鹿原》。然而，过去在学校因为事情众多难以聚焦到“读闲书”上，所以 2022 年的 2 月开启这部书的阅读，走入白鹿原的广袤天地之后就一度搁置。 直到 2023 年毕业工作后的某个瞬间，决定要重拾读书计划之后才想起在一年前的某个时间我曾读过这本书的三分之一。过去了这么长时间，我还能明确地记得我读到三分之一的节点是白灵和鹿兆海用掷铜钱的形式分别投身国共两党追求理想而愉快分别的场景，再次拾起此书时两人分别时欣喜的场景还历历在目，但后来的结局竟是如此，实在令人惋惜… 过去没有写读后感的习惯，最多在中学时因为看书中人物罹难后过于激动而在 QQ 空间发动态抒怀。但不得不说毕业后独居的生活给予了我更多的思考时间，让我能够在品读作品之余思索其中深意，感慨书中角色之悲壮或卑劣，也算是双面硬币里好的一面了。 向外输出是向内消化的高级姿态，我希望通过写出自己的感受加深自己对作品的理解。 白鹿原之白鹿白鹿精魂《白鹿原》中最具神话色彩的便是多次出场的白鹿精魂，每次露面总能带来祥瑞之兆：是白嘉轩看中天字宝地时的灵光乍现，是久旱逢甘露的峰回路转，是瘟疫肆虐时的杀毒祛邪，更是白灵托梦时的凄惨和不舍。白鹿是白鹿原的神，“白毛白腿白蹄，那鹿角更是莹亮剔透的白”，如此洁白无瑕的形态本身就预示着其极其圣洁的存在。 因为白嘉轩是主角，所以白鹿总是围绕着他腾挪欢跃，事实上每个人都有自己的白鹿，都有属于自己的精灵。白鹿的存在是预示着灾厄、苦难和煎熬终将抵达终点，上天会眷顾勤劳勇敢的人们。白嘉轩一辈子行事光明磊落，从不堕入歪门邪道，坚毅刚强，从不落人把柄，成人后作为一族之长秉持着家族的尊严和荣耀，尽管有时其作为族长摆出的架子让人看起来封建古板、不尽人意，但其行为处事最后往往能够收获不坏的结果，足以深孚众望，让他在几十年的族长位子上坐得稳稳当当。贯穿全书的是白嘉轩如同上帝一般的全局视角，无论经历什么灾祸或是幸事，总能够达到波澜不惊、宠辱偕忘的境地，只有在亲人遭遇苦难和不幸时才会流露出一丝失措和动容。我无法想象他是用一种怎样强大的心态来面对周遭世事的，是半生的经历让他有了足够的见识阅历不至于慌张，还是心中一直装着何种信仰？我不认为我在知天命之年能有他那般姿态，或者永远不会。或许白嘉轩和白鹿一样，他们的存在是这整部作品里唯一不现实的意象吧。 白和鹿白嘉轩和鹿子霖的家族恩怨贯穿了整部作品，虽然众多事件仅发生在白鹿原上的小村落里，但其中的复杂程度远超我所看过的宫斗剧。族长白嘉轩取了七房妻子才最终留下后人，令人可笑又可叹；他为了得到天字号宝地，不惜跟鹿家以多换少，双方都以为自己稳赚不赔······ 白嘉轩总是以德报怨，以德服人，不求功名，爱护族人，有底线有原则，虽然思想保守不求变革，但把众多家风传统很好地传承给了下一代，文武义三兄弟都沐浴在这种家风之中四平八稳地生活着，少走弯路。 而鹿子霖则是在相反的方向几乎走到了极端。因为族长位置始终被白家占据，鹿子霖为了“平衡”这种局势，始终极为贪恋权力，从乡约做到保长，坏事做尽。欺上瞒下，狐假虎威，没有底线，贪恋财色，色厉内荏，可以形容他的贬义词汇实在太多，但不得不认清的是：或许他的子集才是彼时此地较为常见且现实的封建家长形象。乐观来讲，我相信不是所有人都有他那么坏，但他的坏是众人之恶的集合，把他拆开揉碎了，就是白鹿原上的所有普通人。 鹿子霖始终期望能够在面子和里子上赢过白嘉轩，但结果总是过犹不及。直到最后鹿子霖被白孝文主持的枪毙大会吓疯后在路边捡拾吃食，用疯癫的语气询问路过的白嘉轩是否要尝尝他的珍馐美味，这场持续半个世纪的与白嘉轩的争斗才遗憾告负。此时的白嘉轩也叹息坦白道他这辈子光明磊落，唯独只背着鹿子霖做过一件对不起他的事，也不过是买下鹿家一块地用来做坟。鹿子霖父亲被土匪杀害时他没疯，鹿子霖二儿子鹿兆海战死时他没疯，鹿子霖锒铛入狱坐了两年大牢他没疯，偏偏在解放后白孝文作为县长主持的批斗会后发疯，不是因为他不够坚强或是胆小如鼠，而是他奋斗了一生的、希望赢过白家的目标，被白嘉轩的从容不迫、白孝文的位高权重和靠山田福贤的倒塌而变得不可实现。压在鹿子霖心中的大山没有移走反而更加厚重，常年如履薄冰的他终于堕入了冰冷的水中。 人与原“白嘉轩就是白鹿原”，这是陈忠实先生在《白鹿原》的后记中提到的。这一说法也自然地解答了我的疑惑，为什么我认为白嘉轩是如同神一样的存在，正因为他在任何时候都能足够稳定、冷静和从容地分析决断，体面地处理家里和族中的大小事务，令人心悦诚服，到头来发现其所做出的决断带来的结果总是不赖。此般沉着稳重和波澜不惊俨然如黄土高原积攒千万年巍然不动的黄土，深厚且沉静。虽然没有去过西北，没亲眼见过黄土高原，但凭借零星的影视作品和我单薄的想象力，也能够在脑海中描绘其壮观雄浑的景象。 田小娥和他的四个男人我讨厌田小娥。她是个不知廉耻、人人唾弃的“婊子”，是宁静乡村里和谐生活的毒药，是男人淫欲贪欲的放大器。他一生和很多男人有过纠葛，吸引和释放着男人的欲望，自由且作恶的一生被公公残酷终结，最终化作魂魄也被镇压在高塔之下，不得安生。田小娥是自由的，是进步的，是开放的，但在那个年代自由、进步、开放的就是“婊子”。而封建社会的女人家最好就是安安分分嫁出去，在婆家勤勤恳恳服侍丈夫和公婆。可恨之人亦有可怜之处，田小娥错就错在于那样的年代投胎成为了白鹿原上的女子。 郭举人田小娥作为郭举人的小妾，并没有得到郭举人的一丝宠爱或“临幸”，而被当做了工具——“泡枣”的容器。读到这里我感到非常震撼，一是感叹旧社会底层的人不配做人，二是认为这样的食物不健康不卫生，让我作呕。我起初其实非常不理解家境不差的田秀才为什么会把自己的女儿委身到年近半百的郭举人家中去，读书人应当是知书达理的，是思想进步开放的，为什么会做出这样不可理喻的决定的？后来我明白了，田秀才读的书不能让他体恤他人、理解女儿，只是让他成为庸儒，成为唯上的学问家，宁可和其他读书人向上兼容地“联姻”，也不愿向下从庄稼汉里找亲家。这样迂腐的学问早就应当和这样迂腐的王朝一同被推到历史的垃圾桶里。 黑娃前半生坏事做尽，后半生浪子回头。 黑娃，鹿兆谦，从小到大没干过一件体面、冷静的事情，但在百年前的农村环境下，其敢于和田小娥私奔回家甚至期望和田小娥拜堂成亲，已经表现出其独特的勇气和魄力。黑娃拥有一种未经驯化的、没有规则的、充满棱角的勇气和魄力，这样的特质也让他之后闹农协、搞暴动、入军队、当土匪等一些行为都变得顺理成章自然而然。他的勇敢是值得赞赏的，但其对田小娥始乱终弃的行为间接导致了田小娥的进一步堕落。黑娃闹农协出走之后几乎没有回过白鹿原，更不用说再回到那个冰冷又温暖的窑洞。他们的窑洞今后会有若干的、爱黑娃的、憎黑娃的男人会踏足，可黑娃在田小娥死之前却始终不曾回来过。 黑娃从山里被招安到保安团后发生的转变我愿称为奇迹，突然从直率莽撞、目无法纪的土匪变成了文质彬彬、一心想学的温柔君子。向贤者朱先生认真求学并得到了朱先生的高度赞扬，“我最好的弟子竟然是一个土匪”。而我以为黑娃会有个很好的结局，可是没想到和白灵一样，好人没有落到好的下场。属实让我觉得惋惜。 鹿子霖鹿子霖与白鹿村及周边村子的几十名女子有染，据说如果其私生子、干儿子齐聚一堂的话需要坐好几桌。田小娥便是这些与鹿子霖有染的女子之一。但鹿子霖对田小娥完全没有情感，就是嫖客和妓女的关系，或者是工人和工具的关系，虽然在这样的关系当中他们也曾和谐和快乐过。鹿子霖周期性地来到田小娥的窑洞与其偷情，顺便施以小恩小惠，让田小娥糊涂地以为这段关系能长久持续。快乐并不长久，美人计得逞之后的鹿子霖得意忘形：田小娥在她眼里从来都不是能够平等交流的人。“兔死狗烹”的想法流露出来之后田小娥给了他一巴掌，这整本书唯一的一次女人扇向男人的耳光，竟然是田小娥挥向鹿子霖的。 白孝文白孝文完全沦陷于荡妇田小娥没有底线没有原则的攻势，这是被包办婚姻的他没有品尝过的激情与爱意。白嘉轩给儿子们娶媳妇时看重的是这位女子能够给家庭带来什么，并不会考虑儿子们的喜恶，娶回来的媳妇自然就不一定得到儿子的疼爱。所有的包办婚姻都是如此。先结婚生子再谈感情，或者不用谈感情的情况比比皆是，两人举案齐眉、相敬如宾，客客气气地深受家长喜爱，但就是不讨白孝文喜欢。而田小娥的身体和话语则让白孝文魂牵梦绕挥散不去，以至于最后跟家里闹得妻离子散，分家后变卖家产也不给他的原配夫人一分一毫，甚至其饥荒饿死也不曾引来白孝文的一丝悔恨和一滴泪水。 白孝文是田小娥罪恶的巅峰，也是其性命走向终点的引线。忠厚善良的鹿三为了结这一切荒谬的闹剧，在一个夜里把田小娥给杀死了… 鹏海之于白灵白灵的死让我意难平但又难以评价，但写到这里其实已经没有太多表达欲了。不知道为什么在阅读白灵、鹿兆海和鹿兆鹏的故事情节时我总能联想到几年前玩过的《隐形守护者》，可能国共两党从合作到决裂，国民党反动派肆意屠杀异见者的情节总是让人想到谍战吧，但不同的是白灵是这部谍战片中的女主角。鹿兆海像个小孩，革命上和感情上跟白灵打了一辈子的赌；白灵却早就长大成人，在战乱的年代选择了革命爱情。白灵是崭新的、向上的、自由的、进步的、顽强的、不屈的、喷薄的、新中国的新一代的力量，她的选择必定成功。 最后，为什么鹿兆鹏与怀孕中的白灵告别后再也没有出现，没有救下因猜忌而惨死的白灵，是我读这部作品的不解和遗憾。 总结《白鹿原》描绘了从清末到新中国近半个世纪的时间跨度下，白鹿原中白家和鹿家两代人的牵扯和纠葛，刻画了白嘉轩、白孝文、鹿子霖、田小娥、鹿兆鹏、鹿兆海、黑娃等栩栩如生的形象，展现了国共两党从北伐蜜月期到国民党临阵倒戈的暗流涌动和真刀真枪，揭示了旧社会旧中国把女人当工具，把穷人当牲口的丑恶面目，由点及面地从白鹿原小家族入手讲述了整个中国农村环境的变迁，是一部恢弘的史诗，也是一部写实的影集，值得思索和品味。 题外话，看完《平凡的世界》和《白鹿原》两部作品后，真心希望自己能够抽出时间游览大西北，领略大家笔下的黄土高原是何等的伟壮。","link":"/2024/01/01/WhiteDeerPlain/"},{"title":"为什么我要写博客？","text":"内外因素我喜欢记录我很喜欢记录，就像首页那句话说的“有着记录的想法，没有记录的时间”一样：我喜欢把生活里有趣的、激发自己思考的事物都记下来，倒不是为了写给谁看或者写给未来的自己看，光是写下来的过程会让我觉得很好，不知道怎么用语言形容的一种“满足感”；但是在学校的时候事情实在是太多了，学习、社工、项目还有各种琐碎的事情让我根本没有时间把所想所见记录下来，所以也就有了这个博客里年更的情况出现了。 2019年的12月31日，我在自己的非主流QQ空间发了一篇名为《别了，我的一零年代》的日志，回顾了一下自己的中学和大学本科时期的得与失，2020年年底实在是太忙了，没能够再写一篇“年终总结”。不过现在想起来也不是很遗憾，因为2020年不是很能激起我的记录欲。好！在！已经研一，兵荒马乱的研一上学期也已经度过了，至少未来一年半内不会有太多课程上的压力，这样可以让我有更多连续的时间能够用来记录。这是让我非常开心的，我猜我今后会多写一些东西在博客上吧，应该会。 我应该记录“学计算机的人应该有一个博客”是我从大学入学时就有的一个想法，这样朴素的情感大概是在我拜读了阮一峰和廖雪峰等大神博客之后就在心里扎根了的。确实，不管是大一入学、大二做课程大作业、大三在校外实习，通过查询和浏览博客是我解决特定问题的主要方式。所以我觉得自己应该也要成为这样的一个“博主”，虽然没有特别亮眼的技术实力，但是通过写博客督促自己不断的学习也是一件足够酷且有益的事情。 还有一件事情值得一提，在写《Github Actions的基本使用》时其实我是边学边写，一开始觉得有个地方是 GitHub Actions 的 Bug ，迫于无奈和夜深，发布博客之后就赶紧溜去睡觉了。第二天回看博客的时候一眼就发现了问题所在，这样的特点也从另一方面激励我继续写博客。 “记录”对我是有好处的。 近期的一点牢骚清华的竞争氛围太强了：每个人都是高中的佼佼者，到了大学有的人依旧游刃有余，有的人就力不从心了，不管排名保持高中的状态还是变好或变坏都是非常正常的事情。找准自己的定位和方向，保持努力就可以了，没有什么比热情更重要。在知乎上经常能看到“清华XX系大四了还一事无成怎么办”这样的问题，如果要我回答的话我确实无法组织出一段话来回答这样的问题，在提问者的上下文里我其实也是一事无成的。 跟人比较确实上头，确实会增加焦虑。可是我不会把自己推到这样的焦虑当中，我不喜欢跟别人比，我只希望自己可以充实和从容，不用妄自菲薄，也不要自以为是。自己只要保持这样的心态和步调就不太在意身边的压力了。 之后写点什么之前有的两个标签是“学习”和“瞎写”，现在觉得“瞎写”有点莫名其妙，之后打算换成“随笔”。有考虑增加一两个标签（例如“游记”和“相册”等），也希望自己能够维持“学习”和其他标签博客的比例。 最后，希望2021年一切都好。 迟到的新年小作文","link":"/2021/01/16/WhyBlog/"},{"title":"为什么前端开发要选择 GraphQL","text":"这篇博客其实是以一次公司内的技术分享为基础做的调研和总结归纳，包含了我自己很多不成熟的观点看法。这次分享主要是想向新同事介绍为什么我们选择在项目中大规模使用 GraphQL 而不是更传统更简单的 RESTful API。 GraphQL 是什么在上一篇有关 GraphQL 的博客里，我简单地说明了 GraphQL 的定义及其大致用途，贴了官网链接就开始介绍我使用 GraphQL 的“更优雅的”方式，对 GraphQL 本身描述得并不多。这里又贴一下英文的定义：A query language for your API GraphQL is a query language for APIs and a runtime for fulfilling those queries with your existing data. GraphQL provides a complete and understandable description of the data in your API, gives clients the power to ask for exactly what they need and nothing more, makes it easier to evolve APIs over time, and enables powerful developer tools. 划重点，它是一种查询语言和使数据可查询的运行时。作为一种语言，它有自己的语法，能够定义Type, Enum, Input, Fragment, Query, Mutation等元素，熟悉 Typescript 的朋友会对此感到亲切。而在前端开发中需要重点关注的是以下几个部分： Schema: 可以类比为整个 API 的全貌，通过类型系统定义了所有的类型和方法，描述了如何进行数据的查询和修改； Query: 是 Schema 中定义的方法，用于查询数据，无副作用，在后端并行执行； Mutation: 是 Schema 中定义的另一类方法，用于修改数据产生副作用，在后端串行执行； Operation: 是客户端定义的方法，命名和参数自定义，用于调用 GraphQL 的「查询」 根据以上主要元素，使用 GraphQL 进行开发的大致范式如下图所示，当然在这里我简化了后端的工作。首先后端（至少）需要将 API Schema 定义并提供到指定端点上，前端开发者将 Schema 拉取到本地当作接口文档或者是编写 Operation 时代码补全的蓝本，需要调用接口时向指定端点传递 Operations 及其对应参数即可，整个过程十分丝滑。 虽然但是，上述过程本质还是向某个 URL 地址以某种 HTTP 方法传递了某些参数且得到了某些返回数据，和传统的 RESTful API 有什么区别呢？ RESTful API 的劣势RESTful API 是什么下面这是 REST 的定义，比较晦涩难懂。符合 REST 规范的 API 被称为 RESTful API，特点是使用 URI 和 HTTP Method 来区分接口方法。 REST is an acronym for REpresentational State Transfer and an architectural style for distributed hypermedia systems. 规范的 RESTful API 将资源放在 URI 中，如 /api/v1/articles 表示「文章」资源；用 HTTP Method 方法来表示动作语义，如 GET 表示获取，POST 表示更新，PUT 表示新增，DELETE 表示删除等，但是 RESTful 的规范很难实现或维持。我见过很多公开的 API 都直接将动作语义包含在 URI 里，而真正应该用来表达动作的 HTTP Method 则只用 GET 和 POST。最近刚好在接微信的接口，正好拎出来批评一下。 不规范使用 RESTful API 的问题因为 RESTful API 规范很难在开发过程中贯彻执行，所以下面我就归纳了目前常见 RESTful API 的缺陷： 容易过度获取数据或获取数据不足 不支持一次网络请求调用多个接口 前端需要知道所有接口服务的地址，强依赖于接口文档 导致 HTTP Method 滥用，如查询表单字段稍多就写成了 POST 接口 前端开发强依赖于后端，后端接口变化前端反应剧烈 当增加新功能时后端需要整合多个微服务的数据提供给前端，即需要数据网关 接口返回值没有类型，无法利用 TS 的优秀特性 难以编写接口文档，虽然有 OpenAPI/Swagger 等工具，但编写起来仍然很麻烦 API 升版本会直接改变端点 URL，对前端开发影响较大 GraphQL 的改进GraphQL 的诞生可以说是刀法精准，每一处都正中 RESTful 的弱点： 需要什么信息就定义什么字段，不多不少 支持一次请求调用多个接口 所有接口的 URL Endpoint 统一 进一步促进前后端解耦和 API 迭代优化，消除 API 版本 给接口赋予类型系统，代码即文档，无需 OpenAPI 式的补丁式接口说明 支持在线调试和文档查询 IDE 如 GraphiQL 和 GraphQL Playground 目前越来越多公司都开始使用 GraphQL API，包括但不限于 Meta，Github，PayPal，Netflix，Airbnb 还有国内的快手等。 GraphQL 给前端的新可能获得更大的自主性 数据存取上比起 RESTful API 完全隶属于后端，使用 GraphQL 给前端开发更多的自主性 需要用什么数据，用多少数据，怎么用数据以前端为主；后端只需要将 Schema 这个「全集」定义好、测试好 页面增加或减少信息呈现、数据字段改名等操作都可以在前端独立完成 GraphQL Schema 应当是前后端开发者共同制定出来的，强化前端开发在数据层面的重要性 充分利用类型系统的优势 利用代码生成工具，前端开发时可以将 GraphQL 的 Schema 拉取下来，并且参照其类型系统生成对应的 TS 代码，此类工具集大成者是 GraphQL Code Generator 兼容性好：只生成 API 代码，不涉及页面模板，React、Vue 和微信小程序都可以支持，基本涵盖目前需要接触所有类型的前端开发 自由度高：code generator 支持多种插件，可根据开发习惯和偏好进行选择 可维护性强：使用 TS 调用接口后不会在代码逻辑中出现任何与接口名称、URL地址、HTTP方法相关的任何硬编码字符串；TS 指定接口参数返回值，避免许多 JS 中常见的运行时错误 声明式的语言提高确定性GraphQL 的查询语言是 type { …fields } 这样声明式的，在 Operations 中定义了什么字段，一切正常的情况下就会返回相应结构的字段，所见即所得。而且，声明式的查询使得接口的确定性更高，消除歧义，前端开发不用猜接口返回的信息包含什么数据。 总结因为从一开始接触 Web 应用开发以来我就开始使用 GraphQL，所以反而是 RESTful API 没有大规模的使用过（只用在自己的玩具应用），对它的认识没有特别深入。但是直观感受是 GraphQL 对前端开发来说只有好处没有坏处，倒是后端实现起来 GraphQL 成本比 RESTful 高一些，毕竟要定义 Schema 和各式各样的方法、类型和参数，比直接定义 URI + Method + Params 的方式要复杂一点。但是一旦 RESTful API 要规范化规模化的话，应该也需要投入大量时间编写接口文档，这个时候两种 API 实现方式的成本就相差无几了。而开发体验上 GraphQL 是完胜的，所以我希望越来越多企业转向 GraphQL API。","link":"/2022/06/03/WhyWeChooseGraphQL/"},{"title":"当我执行 kubectl create 时发生了什么[译]","text":"翻译自 What happens when … Kubernetes edition!。我认为这篇文章写得生动有趣，且在关键位置都给出了有价值的链接，引导进一步的阅读学习，让我有了重读并翻译的冲动。 如果我希望往 Kubernetes 集群当中部署 nginx，我大概率会在命令行输入下面这样的命令并敲下回车键： 1kubectl create deployment nginx --image=nginx --replicas=3 几秒之后，我应该能看到三个 nginx 的 pod 散布在集群的工作节点上。这很神奇！但这个过程背后究竟发生了什么？ 关于 Kubernetes 的惊人的特点是，它通过用户友好的 API 处理工作负载的部署。其中的复杂性被简单的抽象隐藏起来。但为了充分理解它所提供的价值，了解其内部工作原理也是很有用的。本指南将引导您了解从客户端 kubectl 到 kubelet 的请求的完整生命周期，并在必要时链接到源代码（或者相关文档和博客）来进一步说明正在发生的事情。 这是一份不断修订的文档。如果您发现可以改进或重写的地方，欢迎贡献！ kubectl校验和生成器好的，我们开始吧。我们刚刚在终端里敲击了回车键，现在会发生什么？ 首先 kubectl 会进行客户端校验，该过程保证了应当出错的请求尽早地出错，而不是在发送给 kube-apiserver 之后再返回错误，例如创建了一个不支持的资源或者一个异常的镜像名。这个校验过程通过减少不必要的负载提升了系统的性能。 校验完成后，kubectl 开始组装将要发送到 kube-apiserver 的 HTTP 请求。任何希望访问或者改变 Kubernetes 系统状态的请求都会经过 API server 并最终与 etcd 进行交互。kubectl 也一样，为了构建这样的 HTTP 请求，kubectl 使用了名为生成器的抽象来完成序列化过程。 可能不太明显的是，我们实际上可以使用 kubectl run 指定多个资源类型，而不仅仅是 Deployments。为了实现这一点，如果没有使用 --generator 标志显式指定生成器名称，kubectl 将推断出资源的类型。 例如，具有 --restart-policy=Always 标志的资源被视为 Deployments，而具有 --restart-policy=Never 的资源被视为 Pods。kubectl 还会确定是否需要触发其他操作，例如记录命令（用于滚动更新或审计），或者该命令只是通过 --dry-run 标志来指定的模拟运行。 在意识到我们想要创建一个 Deployment 之后，kubectl 将使用 DeploymentAppsV1 生成器根据我们提供的参数生成一个运行时对象。“运行时对象”是一个通用术语，用于表示资源。 API 组别和版本的协商在继续之前需要指出的是，Kubernetes 使用 “API 组” 这样的版本化 API。API 组的目的是将相似的资源进行分类，以求更容易理解。它还提供了一个比单一的单体 API 更好的选择。Deployment 的 API 组名为 apps，最新的版本是 v1。这就是为什么在 Deployment 的清单的顶部需要使用 type apiVersion: apps/v1。 无论如何，在 kubectl 生成运行时对象之后，它开始查找适当的 API 组和版本，并组装一个版本化的客户端，该客户端知道资源的各种 REST 语义。这个发现阶段被称为版本协商，其中 kubectl 扫描远程 API 上的 /apis 路径，取回所有可能的 API 组。由于 kube-apiserver 在此路径上以 OpenAPI 格式公开其模式文档，所以客户端可以轻松完成 API 发现。 为了提高性能，kubectl 还将 OpenAPI 模式缓存到 ~/.kube/cache/discovery 目录中。如果你想看到这个 API 发现的过程，可以尝试删除该目录，并运行一个带有最大值 -v 标志的命令，之后可以看到所有试图找到这些 API 版本的 HTTP 请求。有很多！ 最后一步是实际发送 HTTP 请求。一旦发送请求并收到成功的响应，kubectl 将根据预期的输出格式打印出成功消息。 客户端认证在之前的步骤中我们没有提到客户端认证，这是在发送 HTTP 请求之前处理的，所以现在让我们来看看这个过程。 为了成功发送请求，kubectl 需要进行身份验证。用户凭据基本上都存储在位于磁盘上的 kubeconfig 文件中，但该文件可以存储在不同的位置。为了定位它，kubectl 执行以下操作： 如果提供了 --kubeconfig 标志，则使用该文件。 如果定义了 $KUBECONFIG 环境变量，则使用该变量。 否则，查找推荐的主目录，如 ~/.kube，并使用找到的第一个文件。 解析文件后，kubectl 确定要使用的当前上下文、要指向的当前集群以及与当前用户关联的任何身份验证信息。如果用户提供了特定标志的值（例如 --username），则优先使用这些值，并将覆盖 kubeconfig 中指定的值。一旦获得这些信息，kubectl 将补全客户端的配置，以便适当地组装 HTTP 请求： x509 证书使用 tls.TLSConfig 发送，这也包括根CA Bearer token 放置在 “Authorization” HTTP 头中发送 用户名和密码通过 HTTP 基本身份验证发送 OpenID 身份验证过程由用户在之前手动处理，会生成一个像 Bearer token 一样发送的 token kube-apiserver身份验证我们的请求已经发送出去了，太棒了！接下来呢？该轮到 kube-apiserver 出场了。正如我们之前提到的，kube-apiserver 是客户端和系统组件用来持久化和获取集群状态的主要接口。为了开展其工作，它需要能够验证请求者的身份。这个过程被称为身份验证。 kube-apiserver 如何对请求进行身份验证呢？当服务器首次启动时，它会查看用户提供的所有 CLI 标志，并组装一个合适的身份验证器列表。举个例子：如果传入了 --client-ca-file 参数，它会添加 x509 身份验证器；如果看到 --token-auth-file 参数，它会将 token 身份验证器添加到列表中。每次接收到请求时，它会通过身份验证器链验证请求，直到有一个成功为止： x509 验证处理程序将验证 HTTP 请求是否使用由 CA 根证书签名的 TLS 密钥进行加密。 bearer token 验证处理程序将验证 HTTP 请求中提供的令牌（在 HTTP Header 中 Authorization 字段中指定）是否存在于 --token-auth-file 参数指定的磁盘文件中。 basic auth 验证处理程序将类似地确保 HTTP 请求的基本身份验证凭据与其自身的本地状态匹配。 如果每个身份验证器都失败，该请求将失败，并返回一个聚合错误。如果身份验证成功，Header 中 Authorization 字段将被删除，并将用户信息添加到其上下文中。这使得之后的步骤（例如鉴权和准入）能够访问先前确立的用户身份。 请求鉴权好的，请求已经发送出去，kube-apiserver 已成功验证我们的身份。松了一口气！然而，我们还没有结束。我们可能是我们自己说的那个身份，但我们是否有权限执行此操作呢？毕竟，身份和权限是不同的。为了让请求继续执行，kube-apiserver 需要对请求进行鉴权。 kube-apiserver 处理鉴权的方式与身份验证非常相似：根据输入的标志，它将组装一个鉴权器链，针对每个传入的请求依次运行。如果所有鉴权器都拒绝请求，请求将导致 Forbidden 的响应，并且不再继续处理改请求。如果单个鉴权器批准请求，请求将继续进行。 Kubernetes v1.8 提供的一些鉴权器示例包括： webhook，与集群外的 HTTP(S) 服务进行交互； ABAC，强制执行在静态文件中定义的策略； RBAC，强制执行由管理员作为 k8s 资源添加的 RBAC 角色； Node，确保节点客户端（即 kubelet）只能访问托管在自身上的资源。 可以通过查看每个鉴权器的 Authorize 方法，了解它们的工作原理。 准入控制好的，到目前为止，我们已经通过了 kube-apiserver 的身份验证和请求鉴权。那接下来呢？从 kube-apiserver 的角度来看，它相信我们是谁并允许请求继续执行，但在 Kubernetes 中，系统的其他部分对于什么应该和不应该发生有严格的要求。这时候准入控制器就开始发挥作用了。 虽然鉴权的重点是判断用户是否有权限，但准入控制器拦截请求以确保其符合集群的更大范围的预期和规则。它们是对象持久化到 etcd 之前的最后一道控制屏障，因此它们封装了剩余的系统检查，以确保操作不会产生意外或负面的结果。 准入控制器的工作方式类似于验证器和鉴权器，但有一个区别：与验证器和授权器链不同，如果单个准入控制器校验失败，整个链条将中断，请求将失败。 准入控制器设计的真正精妙之处在于其专注于促进可扩展性。每个控制器都存储为 plugin/pkg/admission 目录中的插件，并且被设计为满足一个小接口。然后，每个控制器都被编译到主要的 kubernetes 二进制文件中。 准入控制器通常按照功能分为资源管理、安全性、默认设置和引用一致性几类。以下是一些负责资源管理的准入控制器的示例： InitialResources：根据过去的使用情况为容器的资源设置默认限制。LimitRanger：为容器的请求和限制设置默认值，或对某些资源配置上限（例如内存不超过 2GB，默认为 512MB）。ResourceQuota：在命名空间内统计或拒绝分配一定数量的对象（pod、rc、service 负载均衡器）或总消耗的资源（CPU、内存、磁盘）。 etcd到目前为止，Kubernetes 已经完全检查了传入的请求，并且允许其继续执行。接下来，kube-apiserver 对 HTTP 请求进行反序列化，从中构建运行时对象（类似于 kubectl 的生成器的逆过程），并将它们持久化到数据存储中。让我们来详细解析一下这个过程。 kube-apiserver 怎么知道接受我们的请求时该做什么呢？在任何请求被处理之前都有一系列复杂的步骤。让我们从起点开始，也就是二进制文件首次运行时： 当 kube-apiserver 二进制文件运行时，它创建一个服务器链，用于支持 apiserver 的聚合。这只是支持多个 apiserver 的一种方式，我们不需要担心这个。 在这个过程中，会创建一个通用的 apiserver 作为默认实现。 生成的 OpenAPI 模式补充了 apiserver 的配置。 kube-apiserver 然后遍历模式中指定的所有 API 组，并为每个 API 组配置一个存储供应器作为通用的存储抽象，kube-apiserver 在访问或修改资源状态时需要与其进行交互。 对于每个 API 组，它还会遍历每个组版本，并为每个 HTTP 路由安装 REST 映射。这让 kube-apiserver 能够正常映射请求，并在找到匹配项后把请求代理给正确的逻辑处理。 对于我们的特定用例，会注册一个 POST 处理程序，该处理程序将进一步代理给一个创建资源的处理程序。 截至目前，kube-apiserver 已经完全了解了存在的路由和内部映射，在请求到来时能将其转发到正确的处理程序和存储供应器。现在设想我们的 HTTP 请求已经到达： 如果处理程序链能够将请求与一组模式匹配（即我们注册的路由），它将把请求分发到为该路由注册的专用处理程序。否则，它将回退到基于路径的处理程序（例如调用 /apis 时的情况）。如果没有为该路径注册处理程序，则会调用一个未找到的处理程序，导致返回 404 错误。 幸运的是，我们有一个名为 createHandler 的注册路由！它的工作原理是什么呢？首先，它会解码 HTTP 请求并执行基本验证，例如确保提供的 JSON 与我们对版本化 API 资源的预期相符。 进行审计和最终的准入。 通过代理给存储供应器将资源保存到 etcd 中。通常，etcd 键的形式为 &lt;namespace&gt;/&lt;name&gt;，但这也是可配置的。 捕获任何创建时的错误，最后存储供应器执行 get 调用以确保对象实际上已创建。然后，如果需要进行其他的最终处理，它会调用任何创建后(Post-create)处理程序和装饰器。 构建并返回 HTTP 响应。 步骤很多！通过追溯这些步骤，我们能看到 apiserver 实际上做了多少工作。所以总结一下：我们的 Deployment 资源现在存在于 etcd 中。但是其中还有一些尚未完成的流程，所以目前我们还没办法看到它… 初始化器在将对象持久化到数据存储中后，只有在一系列初始化器运行完成之后，该对象才会对 apiserver 或调度程序完全可见。初始化器是与资源类型相关联的控制器，在资源对外界可见之前对资源执行相关逻辑操作。如果某个资源类型没有注册任何初始化器，则会跳过此初始化步骤，资源会立即对外可见。 正如许多优质的博客文章介绍的，这是一个强大的功能，因为它让我们能够执行通用的引导操作。例如： 将代理边车容器注入到公开端口 80 的 Pod 中，或者具有特定注释的 Pod 中。 向特定命名空间中的所有 Pod 注入带有测试证书的卷。 如果一个 Secret 的长度小于 20 个字符（例如密码），阻止其创建。 initializerConfiguration 对象允许我们声明哪些初始化器应该针对特定的资源类型运行。想象一下，如果我们希望在每次创建 Pod 时运行自定义的初始化器，我们可以这样做： 12345678910111213apiVersion: admissionregistration.k8s.io/v1alpha1kind: InitializerConfigurationmetadata: name: custom-pod-initializerinitializers: - name: podimage.example.com rules: - apiGroups: - &quot;&quot; apiVersions: - v1 resources: - pods 创建完这个配置后，它会将 custom-pod-initializer 添加到每个 Pod 的 metadata.initializers.pending 字段中。初始化器控制器会定期扫描新的 Pods。当初始化器检测到一个 Pod 的 pending 字段中有自己的名称时，它会执行相应的逻辑。完成逻辑处理后，它会从 pending 列表中移除自己的名称。只有列表中第一个名称的初始化器才能对资源进行操作。当所有的初始化器完成逻辑处理并且 pending 字段为空时，该对象将被认为已经初始化。 细心的你可能已经发现了一个潜在的问题。如果资源在 kube-apiserver 中不可见，用户自定义的控制器如何处理这些资源呢？为了解决这个问题，kube-apiserver 提供了一个 ?includeUninitialized 查询参数，它返回所有对象，包括未初始化的对象。 控制循环Deployments 控制器现在我们的 Deployment 记录已存储在 etcd 中，并且任何初始化逻辑都已完成。接下来的步骤涉及设置 Kubernetes 所依赖的资源拓扑结构。我们可以这样想，一个 Deployment 实际上只是一组 ReplicaSet，而一个 ReplicaSet 是一组 Pod。那么 Kubernetes 是如何通过一个 HTTP 请求来创建这样的多层级结构的呢？这其实是 Kubernetes 内置的控制器的作用。 Kubernetes 在整个系统中广泛地使用“控制器”。控制器是一个异步逻辑，用来将 Kubernetes 系统的当前状态与期望的状态进行协调(reconcile)。每个控制器都有自己的任务，并和 kube-controller-manager 组件一起并行运行。让我们先介绍接管工作的第一个控制器，即 Deployment 的控制器。 在 Deployment 的记录存储到 etcd 并初始化后，kube-apiserver 使其对外可见。当这个新的资源可用时，它会被 Deployment 控制器检测到，Deployment 控制器的工作是监听对 Deployment 记录的变动。在我们的例子里，控制器通过 informer 为资源新建的事件注册了一个特定的回调函数（有关此内容的更多信息，请参见下文）。 当我们的 Deployment 首次可用时，这个回调处理程序将被执行，并首先将对象添加到内部工作队列中。当控制器处理我们的对象时，它通过标签选择器查询 kube-apiserver 检查出我们的 Deployment 没有与之关联的 ReplicaSet 或 Pod 记录。有趣的是，这个同步过程是与状态无关的：新的记录和老的记录协调方式相同。 在发现没有对应的 ReplicaSet 或者 Pod 记录后，它会通过一个弹性进程创建一个 ReplicaSet 资源，为其分配一个标签选择器，并给它分配版本号为 1。ReplicaSet 的 PodSpec 是从 Deployment 的配置清单中复制过来的，当然也包括其他相关的元数据。在此之后，有时还需要更新 Deployment 记录（例如，如果设置了处理截止时间）。 之后会更新 Deployment 的状态，并重新进入相同的协调循环，直到 Deployment 达到期望的完成状态。由于 Deployment 控制器只关注创建 ReplicaSet，因此这个协调阶段需要由下一个控制器继续进行，也就是 ReplicaSet 控制器。 ReplicaSets 控制器在前面的步骤中，Deployment 控制器为我们的 Deployment 创建了第一个 ReplicaSet，但我们还没有看到 Pod。这之后 ReplicaSet 控制器将发挥作用！它的任务是监听 ReplicaSet 及其依赖资源（Pod）的生命周期。与大多数其他控制器一样，它通过在特定事件上触发处理程序来实现这个功能。 首先我们来看资源创建事件。当创建了一个 ReplicaSet（由部署控制器负责）时，ReplicaSet 控制器会检查新 ReplicaSet 的状态，并发现当前状态与预期状态之间存在的差异。然后它尝试通过增加 ReplicaSet 的 Pod 数量来调解这个状态。它非常谨慎地创建这些 Pod，确保 ReplicaSet 的突发计数（它从其父级部署继承的）始终保持匹配。 Pod 的也是批量创建的，从 SlowStartInitialBatchSize 开始，每次成功创建后扩大一倍，以一种类似于“慢启动”的方式进行。这样做的目的是减轻同时出现大量 Pod 启动失败时（例如，由于资源配额不足）引发 kube-apiserver 负载过高，同时能够减少不必要的 HTTP 请求。如果组件会失败报错，我们最好以对其他系统组件的影响最小的方式来优雅地失败！ Kubernetes 通过 Owner References（这是子资源中的一个字段，用来引用其父级的 UID）来保证对象的层级结构。这不仅确保一旦由控制器管理的资源被删除，子资源就会被垃圾回收，还为父资源提供了一种有效的方式以避免它们争夺子资源（设想一下两个父级认为它们拥有同一个子资源的情况！）。 Owner Reference 设计的另一个微妙好处是它是有状态的：如果任何控制器重新启动，由于资源拓扑结构独立于控制器，它的宕机状态不会影响更多的组件。这种对隔离的关注也包含在控制器本身的设计中：它们不应该管理它们没有明确声明拥有的资源。控制器应该在所有权的声明中进行选择，并且不干扰、不共享。 无论如何，回到 Owner Reference！有时系统中会出现“孤立”(orphaned)的资源，该情况通常由以下原因导致： 删除了父资源，但没有删除其子资源。 垃圾回收策略禁止删除子资源。 发生这种情况时，控制器将确保孤立资源被一个新的父级资源接管。多个父级资源可以竞争接管子资源，但只有一个会成功（其余的父级资源将收到验证错误）。 Informers正如你可能已经注意到的那样，一些控制器（例如如 RBAC 鉴权器或 Deployment 控制器）需要查询集群状态以正常工作。以 RBAC 鉴权器为例，我们知道当请求到达时，验证器将保存用户状态的初始信息以备后用。然后，RBAC 鉴权器将使用改信息来查询用户在 etcd 中关联的所有角色以及角色绑定。控制器应该如何访问和修改这些资源？在 Kubernetes 中往往通过 informer 来解决。 informer 是一种允许控制器通过简单的订阅存储事件来获取它们关注的资源的设计范式。除了提供良好的抽象外，它还处理了许多细节，例如缓存（缓存很重要，因为它减少了与 kube-apiserver 的不必要的连接，并减少了服务器和控制器端重复序列化的开销）。通过该设计，控制器还可以用线程安全的方式进行交互，而不必担心干扰其他任何人。 有关 informer 在控制器中的工作方式的细节，可以参阅这篇博客。 调度器在上述所有控制器运行完成后，我们在 etcd 中存储了一个 Deployment、一个 ReplicaSet 和三个 Pod，并且可以通过 kube-apiserver 查询到它们。然而我们的 Pod 仍处在 Pending 状态，因为它们尚未被调度到节点上。解决这个问题的最后一个控制器是调度器(Scheduler)。 调度器作为控制平面的一个独立组件运行，并且以与其他控制器相同的方式工作：它监听事件并尝试调解状态。在这种情况下，调度器筛选出 PodSpec 中 NodeName 字段为空的 Pod，并尝试寻找一个适合该 Pod 的节点。 为了找到一个适合的节点，调度器使用特定的调度算法。默认调度算法的工作方式如下： 当调度器启动时，会注册一系列默认的谓词(Predicates)。这些谓词实际上是函数，这些函数根据节点是否适合托管 Pod 来进行过滤。例如，如果 PodSpec 明确要求一定的 CPU 或 RAM 资源，容量不足而无法满足这些要求的节点将被排除在 Pod 之外（资源容量计算为总容量减去当前运行容器的资源请求总和）。 一旦选择了合适的节点，会对过滤后的节点运行一系列优先级函数，以对它们的适合程度进行排序。例如，为了在系统中分散工作负载，调度器会倾向于资源富裕的节点（因为这表示较少的工作负载正在运行）。在运行这些函数时，它会为每个节点分配一个数值等级。然后选择排名最高的节点进行调度。 调度算法找到节点后，调度器会创建一个绑定对象，其 Name 和 UID 与 Pod 匹配，其 ObjectReference 字段包含所选节点的名称，然后通过 POST 请求将其发送到 apiserver。 当 kube-apiserver 接收到此绑定对象时，注册表会反序列化对象并更新 Pod 对象上的以下字段：将 NodeName 设置为 ObjectReference 中的节点名称，添加相关的注解，并将其 PodScheduled 状态条件设置为 True。 一旦调度器将 Pod 调度到节点上，该节点上的 kubelet 就可以开始接管并进行部署。真是令人兴奋！ 提示：自定义调度器时谓词和优先级函数都是可扩展的，并且可以使用 --policy-config-file 标志进行定义。这提供了一定程度的灵活性。管理员还可以在独立的 Deployment 中运行自定义调度器（具有自定义处理逻辑的控制器）。如果 PodSpec 包含 schedulerName，Kubernetes 将把该 Pod 的调度交给已注册在该名称下的调度器。 kubeletPod 同步好的，主要的控制器循环已经完成，呼！总结一下：HTTP 请求通过了身份验证、鉴权和准入控制阶段；一个 Deployment、一个 ReplicaSet 和三个 Pod 资源被持久化到了 etcd 中；一系列初始化程序已经运行；最后，每个 Pod 被调度到了一个合适的节点上。然而到目前为止我们所有推演的状态完全存在于 etcd 中。接下来的步骤涉及将状态分发到工作节点上，这是 Kubernetes 这样的分布式系统的核心目标！接下来的过程是通过一个叫做 kubelet 的组件来实现的。我们开始吧！ kubelet 是在 Kubernetes 集群的每个节点上运行的代理程序，负责管理 Pod 的生命周期等任务。这意味着它处理了从 Pod（实际上只是 Kubernetes 的一个概念）到其构建块（容器）的所有转换逻辑。它还处理与挂载卷、容器日志、垃圾回收等相关逻辑以及许多其他重要事项。 一个便于理解的方法是：可以把 kubelet 看做一个控制器！它会每隔 20 秒（可配置）从 kube-apiserver 查询 Pod，过滤出 NodeName 与该 kubelet 所在节点名称匹配的 Pod。一旦获得该 Pod 的列表，它会通过与自己的内部缓存进行比较来检测新增的 Pod，当比较存在差异时开始同步状态。我们来看看这个同步过程是什么样的： 如果正在创建 Pod（我们的 Pod 正在创建中！），kubelet 会注册一些用于在 Prometheus 中跟踪 Pod 延迟的启动指标。 然后，它生成一个 PodStatus 对象，表示 Pod 当前阶段的状态。Pod 的阶段是其生命周期中的高度总结。阶段包括 Pending、Running、Succeeded、Failed 和 Unknown。生成这个状态相当复杂，所以我们来详细了解一下具体发生了什么： 首先，按顺序执行一系列同步处理程序 PodSyncHandlers。每个处理程序都检查 Pod 是否仍应驻留在节点上。如果它们中的任何一个决定该 Pod 不再属于该节点，Pod 的阶段将变为 PodFailed，并最终被从该节点中驱逐出去。例子包括在超过 activeDeadlineSeconds 后驱逐 Pod（在 Job 资源中常用）。 接下来，根据其初始化和实际容器的状态确定 Pod 的阶段。由于我们的容器尚未启动，容器被归为等待状态。Pod 在拥有等待容器时的阶段为 Pending。 最后，根据容器的状态确定 Pod 的条件。由于我们的容器尚未由容器运行时创建，它将把 PodReady 条件设置为 False。 生成 PodStatus 后，它将被发送给 Pod 的状态管理器，后者负责通过 apiserver 异步更新 etcd 记录。 接下来，一系列准入处理程序会确保 Pod 具有正确的安全权限。这包括校验 AppArmor 配置文件和 NO_NEW_PRIVS 等。在此阶段被拒绝的 Pod 将永远保持在 Pending 状态。 如果指定了 cgroups-per-qos 运行时标志，kubelet 将为 Pod 创建 cgroups 并应用资源参数。这是为了给 Pod 提供更好的服务质量(QoS)。 为 Pod 创建数据目录。这包括 Pod 的目录（通常为 /var/run/kubelet/pods/&lt;podID&gt;）、卷目录（&lt;podDir&gt;/volumes）和插件目录（&lt;podDir&gt;/plugins）。 卷管理器将绑定并等待 Spec.Volumes 中定义的所有相关卷。根据要挂载的卷的类型的不同，某些 Pod 可能需要等待更长时间（例如云存储或 NFS 卷）。 从 apiserver 中查询在 Spec.ImagePullSecrets 中定义的所有密钥，以便后续注入到容器中。 最后由容器运行时(CRI)来运行容器（下面将详细描述）。 CRI 和暂停容器我们现在已经完成了大部分的配置工作，容器已经准备好启动了。负责启动容器的软件被称为容器运行时（例如 Docker 或 rkt ）。 为了更好的扩展性，自 Kubernetes v1.5.0 以来，kubelet 一直在使用称为 CRI（Container Runtime Interface）的概念与具体的容器运行时进行交互。简而言之，CRI 提供了 kubelet 与特定运行时实现之间的抽象接口。通信通过 protocol buffers 完成（类似于更快的 JSON），并使用 gRPC API（一种非常适合执行 Kubernetes 操作的 API 类型）。这是一个非常酷的想法，因为通过使用 kubelet 和容器运行时之间的定义合约，容器编排的具体实现细节变得相对不重要，唯一重要的是合约。这使得可以用最小的开销添加新的运行时，因为我们不需要更改核心 Kubernetes 代码！ 话题岔开太远了，让我们回到部署容器的过程本身。当一个 Pod 首次启动时，kubelet 调用 RunPodSandbox 远程过程调用（RPC）。沙盒 Sandbox 是 CRI 术语，用来描述一组容器，在 Kubernetes 术语中就是一个 Pod。这个术语被刻意地设计得比较模糊，以便对于其他可能实际上不使用容器的运行时（比如基于虚拟化的运行时，其中的沙盒可能是一个虚拟机）也适用。 在我们的例子中，我们使用的是 Docker。在这个运行时中，创建一个沙盒其实是创建一个暂停容器。暂停容器作为 Pod 中所有其他容器的父容器，承载了许多工作负载容器将要使用的 Pod 级资源。这些“资源”是 Linux 的命名空间（IPC、网络、PID）。如果你对 Linux 中容器的工作原理不熟悉，我们进行一个简短的复习。Linux 内核具有命名空间的概念，允许主机操作系统划分出一组专用资源（例如 CPU 或内存），并将其提供给一个进程，就好像它是世界上唯一使用这些资源的进程一样。在这里，Cgroups 也很重要，因为它们是 Linux 管理资源分配的方式（有点像监管资源使用的警察）。Docker 使用这两个内核特性来运行具有足够资源和强制隔离的进程。要了解更多信息，请查看 b0rk 的精彩文章《容器到底是什么》。 暂停容器提供了一种托管所有这些命名空间并允许子容器共享它们的方式。处在同一个网络命名空间的好处是同一个 Pod 中的容器可以使用 localhost 相互引用。暂停容器的第二个角色与 PID 命名空间的工作原理有关。在这些类型的命名空间中，进程形成一个层次树，顶部的初始化进程负责“清理”已经退出的进程。要了解这是如何工作的更多信息，请查看这篇精彩的博客。在创建完暂停容器后，它会被存档到磁盘上，并启动运行。 CNI 和 Pod 通信现在，我们的 Pod 已经有了个基本的骨架：一个承载所有命名空间以实现跨 Pod 通信的暂停容器。但是其中的网络是如何生效的，又该如何进行设置呢？ 当 kubelet 为一个 Pod 设置网络时，它将任务委派给一个名为 CNI 的插件。CNI 代表容器网络插件 Container Network Interface，其工作方式类似于 Container Runtime Interface。简而言之，CNI 是一个抽象层，允许不同的网络供应程序使用不同的容器网络实现。kubelet 通过将 JSON 数据（配置文件位于 /etc/cni/net.d）经过 stdin 传送给相关的CNI二进制文件（位于 /opt/cni/bin）与注册好的插件进行交互。这是一个 JSON 配置的示例： 123456789101112131415{ &quot;cniVersion&quot;: &quot;0.3.1&quot;, &quot;name&quot;: &quot;bridge&quot;, &quot;type&quot;: &quot;bridge&quot;, &quot;bridge&quot;: &quot;cnio0&quot;, &quot;isGateway&quot;: true, &quot;ipMasq&quot;: true, &quot;ipam&quot;: { &quot;type&quot;: &quot;host-local&quot;, &quot;ranges&quot;: [ [{&quot;subnet&quot;: &quot;${POD_CIDR}&quot;}] ], &quot;routes&quot;: [{&quot;dst&quot;: &quot;0.0.0.0/0&quot;}] }} 它还通过环境变量 CNI_ARGS 指定了 Pod 的附加元数据，例如它们的名称和命名空间。 接下来发生的步骤取决于具体的 CNI 插件，我们先来看看网桥(bridge) CNI 插件的工作流程： 首先，网桥插件将在主机的根网络命名空间中设置一个本地 Linux 网桥（bridge），以服务于该主机上的所有容器。 然后，它将在暂停容器的网络命名空间中插入一个接口（一对 veth 的一端），并将另一端连接到网桥（bridge）上。最好将一对 veth 想象成一个大管道：一端连接到容器，另一端在根网络命名空间中，使得数据包在两者之间进行传递。 接下来，网桥插件应该为暂停容器的网卡分配一个 IP 地址并设置路由，这使得 Pod 拥有了自己的 IP 地址。IP 地址分配是委派给在 JSON 配置中指定的 IPAM 提供程序来完成的。 IPAM 插件与主要的网络插件类似：它们通过二进制文件调用，拥有标准化的接口。每个 IPAM 插件必须确定容器接口的 IP/子网，以及网关和路由，并将这些信息返回给主插件。最常见的 IPAM 插件称为 host-local，它从预定义的地址范围中分配 IP 地址。它将状态存储在主机的文件系统上，以确保在单个主机上 IP 地址的唯一性。 至于 DNS，kubelet 将向 CNI 插件提供内部 DNS 服务器的 IP 地址，CNI 插件将确保容器的 resolv.conf 文件设置正确。 上述步骤都完成后，CNI 插件会向 kubelet 返回 JSON 数据说明操作的结果。 跨节点通信到目前为止，我们已经解释了容器如何连接到主机，但主机之间如何通信呢？当位于不同机器上的两个 Pod 想要通信时，就自然会涉及节点间的通信。 通常，节点间通信是通过一种称为覆盖网络（overlay networking）的概念实现的，它是一种在多个主机之间动态同步路由的方式。一个流行的覆盖网络供应者是 Flannel。安装完成后，它的核心任务是在集群中的多个节点之间提供第 3 层的 IPv4 网络。Flannel 不控制容器如何与主机进行网络连接（这是 CNI 的工作，请记住），而是控制主机之间的流量传输。为此，它为主机分配一个子网，并在 etcd 中注册这个子网。随后，它保持集群路由的本地表示，并将传出数据包封装在 UDP 数据报中，确保其到达正确的主机。要了解更多信息，请参阅 CoreOS 的文档。 容器启动所有关于网络的过程都已经介绍了。接下来还剩下什么呢？好吧，我们需要真正地启动工作负载容器。 一旦沙盒初始化完成并处于活动状态，kubelet 就可以开始为其创建容器。它首先启动在 PodSpec 中定义的所有 init 容器，然后再启动主要的容器本身。具体过程如下： 拉取容器的镜像。PodSpec 中定义的加密信息（secrets）都将用于私有的镜像仓库； 通过 CRI 创建容器。沙盒会先从父 PodSpec 中生成一个 ContainerConfig 结构体（其中定义了命令、镜像、标签、挂载点、设备、环境变量等），然后通过 protobuf 将其发送给 CRI 插件。以 Docker 举例，它会反序列化有效的负载并生成自己的配置结构以发送到 Docker 的守护进程 API。在此过程中，它会向容器中注入一些元数据标签，例如容器类型、日志路径、沙盒 ID。 然后，它将使用 CPU 管理器（CPU manager）注册容器。CPU 管理器是 1.8 中的一个新的 alpha 功能，它使用 UpdateContainerResources CRI 方法将容器分配到本地节点上的一组 CPU。 接下来容器被启动。 如果注册了任何后启动（post-start）的容器生命周期钩子，它们将被执行。钩子可以是 Exec 类型（在容器内执行特定命令）或 HTTP 类型（针对容器端点执行 HTTP 请求）。如果 PostStart 钩子运行时间过长、挂起或失败，容器将永远无法变成 running 状态。 回顾好的，终于完成了。 经过所有这些步骤，我们应该在一个或多个工作节点上运行着 3 个容器。所有的网络、卷和加密信息都已由 kubelet 配置完成，并通过 CRI 插件转换为容器。","link":"/2024/01/13/WhatHappensWhenK8s/"}],"tags":[{"name":"Misc","slug":"Misc","link":"/tags/Misc/"},{"name":"前端开发","slug":"前端开发","link":"/tags/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"胡思乱想","slug":"胡思乱想","link":"/tags/%E8%83%A1%E6%80%9D%E4%B9%B1%E6%83%B3/"},{"name":"Github","slug":"Github","link":"/tags/Github/"},{"name":"CI&#x2F;CD","slug":"CI-CD","link":"/tags/CI-CD/"},{"name":"摄影","slug":"摄影","link":"/tags/%E6%91%84%E5%BD%B1/"},{"name":"旅游","slug":"旅游","link":"/tags/%E6%97%85%E6%B8%B8/"},{"name":"小程序","slug":"小程序","link":"/tags/%E5%B0%8F%E7%A8%8B%E5%BA%8F/"},{"name":"部署","slug":"部署","link":"/tags/%E9%83%A8%E7%BD%B2/"},{"name":"Nginx","slug":"Nginx","link":"/tags/Nginx/"},{"name":"文档阅读","slug":"文档阅读","link":"/tags/%E6%96%87%E6%A1%A3%E9%98%85%E8%AF%BB/"},{"name":"React","slug":"React","link":"/tags/React/"},{"name":"NPM","slug":"NPM","link":"/tags/NPM/"},{"name":"Rust","slug":"Rust","link":"/tags/Rust/"},{"name":"后端开发","slug":"后端开发","link":"/tags/%E5%90%8E%E7%AB%AF%E5%BC%80%E5%8F%91/"},{"name":"论文阅读","slug":"论文阅读","link":"/tags/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB/"},{"name":"GraphQL","slug":"GraphQL","link":"/tags/GraphQL/"},{"name":"Vue","slug":"Vue","link":"/tags/Vue/"},{"name":"读后感","slug":"读后感","link":"/tags/%E8%AF%BB%E5%90%8E%E6%84%9F/"},{"name":"K8s","slug":"K8s","link":"/tags/K8s/"}],"categories":[{"name":"学习","slug":"学习","link":"/categories/%E5%AD%A6%E4%B9%A0/"},{"name":"随笔","slug":"随笔","link":"/categories/%E9%9A%8F%E7%AC%94/"},{"name":"游记","slug":"游记","link":"/categories/%E6%B8%B8%E8%AE%B0/"}]}